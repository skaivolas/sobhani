<html>
<body id="chapitre-5607" class="textes chapitre">
<h2 class="suptitle">Chapitre II</h2>
<h1 class="title">Architecture</h1>
<div id="shortcuts"> <a href="#text" title="Text">Text</a> <a href="#notes" title="Anmerkungen">Anmerkungen</a> </div> <div id="text">
<h2 class="section">Volltext</h2>
<div id="widgets" class="withTextSize"></div>
<div class="text wResizable medium">
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">1</span> Le composant syntaxique coïncide avec la jambe du Y, les composants interprétatifs correspondent à <a href="#ftn1">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">1</span>Tout énoncé de la langue associe de façon nécessaire du son et de la signification. Et c’est la tâche de la théorie linguistique que de découvrir et de formuler les principes qui gouvernent cette association. Rendre compte du lien entre le son et la signification suppose que l’on décrive le fonctionnement du système sensori-moteur SM, responsable de la perception et de la production de la parole, le fonctionnement du système conceptuel-intentionnel C-I, responsable de l’interprétation du contenu sémantique et informationnel des énoncés et que l’on caractérise leur interaction. Les différentes théories génératives qui se sont succédé depuis les années soixante ont chacune proposé des modélisations différentes de cette interaction. Dans le modèle d’<em>ATS</em>, la dérivation fait correspondre directement, dans un parcours uniforme, à une représentation du sens, appelée structure D, une représentation du son, résultant de l’application des processus phonologiques à la structure S, elle-même dérivée par transformations de la structure D. Le modèle en Y (<em>Y model</em>), introduit par Chomsky et Lasnik (1977) dans l’article « Filters and control » et sous-jacent au modèle des Principes et Paramètres, pose qu’il existe un composant syntaxique, siège unique de la génération récursive des structures, et deux composants interprétatifs distincts, le composant phonétique/phonologique et le composant sémantique, qui ne se trouvent reliés que par le composant syntaxique.<a class="footnotecall" id="bodyftn1" href="#ftn1">1</a> Le premier génère des représentations de Forme Phonétique (PF), le second des représentations de Forme Logique (LF). L’architecture résultante se donne comme une caractérisation de la Faculté de Langage, système computationnel qui, avec l’aide d’un lexique et d’une mémoire, effectue l’application du son sur la signification et celle de la signification sur le son. Le Programme Minimaliste a, dans un premier temps, adapté le modèle en Y, puis l’a abandonné dans ses versions les plus récentes.</p>
</div>
<p class="texte"><span class="paranumber">2</span>Il vaut la peine de s’arrêter un instant sur l’idée que la Faculté de Langage a une architecture. On peut ici reprendre les observations de Milner (1989) sur « l’épistémologie du dispositif ». Il s’agit pour le linguiste génératif de combiner un ensemble d’hypothèses diversifiées en une sorte de « mise en scène cohérente et totale », de « construire la machine en détail ». Milner propose d’appeler « dispositif » cette « mise en scène détaillée » (p. 139). Selon lui, la grammaire générative est « de part en part et depuis le début une épistémologie du dispositif : les arbres, les transformations, les règles, les composants, les modules, tout cela doit recevoir une interprétation substantielle et constitue un dispositif relié à des propositions réfutables non réfutées de la théorie » (p. 144). Il n’y a pas par contre de dispositif dans la construction théorique proposée par Saussure : « Si tout dérive du concept de signe et de la relation d’opposition, cela veut dire que la théorie linguistique ne rencontre jamais dans ses représentations ce type de positivité qui requerrait qu’on construise la machine en détail » (p. 143-144). Les commentaires de Chomsky sur ses prédécesseurs structuralistes, rapportés au début du chapitre I, reviennent exactement à cela : la linguistique structurale n’a pas fait le choix du dispositif, seule une linguistique du dispositif permet de poser des questions de substance sur le langage.</p>
<h1 class="texte"><a href="#tocfrom1n1" id="tocto1n1">1. Conditions de <em>design</em> optimal</a></h1>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">2</span> On doit distinguer entre le I-langage, abordé comme un objet de la nature, et la représentation qui <a href="#ftn2">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">3</span>Dans le Programme Minimaliste, comme dans les modèles qui ont précédé, la connaissance du langage dans l’esprit du locuteur est conçue comme un système computationnel qui opère sur les éléments du lexique d’une langue pour générer, pour toute expression linguistique, une représentation du son et une représentation de la signification. Le Lexique est d’emblée posé comme une entité disjointe du système computationnel (dans <em>ATS</em>, il est déjà analysé comme une entité séparée du système des règles syntagmatiques). Prises ensemble, ces deux entités constituent la grammaire d’une langue, fonctionnant comme une théorie du I-langage.<a class="footnotecall" id="bodyftn2" href="#ftn2">2</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">3</span> On dit de LF et de PF que ce sont des niveaux d’interface parce que c’est par leur intermédiaire qu <a href="#ftn3">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">4</span>C’est dans <em>MPLT</em> que les notions de <em>convergence</em> et d’<em>échec dérivationnel</em> apparaissent pour la première fois. Une langue détermine, à partir d’un ensemble de choix lexicaux, un ensemble infini de dérivations. Une dérivation <em>converge</em> à l’un des niveaux d’interface si elle produit une représentation satisfaisant le Principe de l’interprétation intégrale (<em>Principle of Full Interpretation</em>, FI) et ne contenant que des objets légitimes, c’est-à-dire « lisibles » et « interprétables » à ce niveau. Une dérivation <em>converge</em> si elle converge aux deux niveaux d’interface, PF et LF.<a class="footnotecall" id="bodyftn3" href="#ftn3">3</a> Sinon, elle <em>échoue</em>. La grammaire produit donc un ensemble infini de paires (π, λ), où π est une représentation phonétique et λ une représentation logique, lisibles respectivement aux interfaces phonologique et sémantique et formant une dérivation convergente (« ensemble infini » fait ici écho à la propriété d’infinité discrète qui, dans <em>ATS</em>, est considérée comme une caractéristique définitoire du langage). Dans <em>MI </em>et <em>BEA</em>, les expressions produites aux interfaces sont désignées sous les étiquettes PHON et SEM, où PHON est la représentation phonologique qui donne des instructions au système sensori-moteur et SEM la représentation sémantique qui donne des instructions au système de pensée. On peut dire que « les théories de PF et de LF cherchent à expliciter la nature de PHON et de SEM » (<em>MI</em>, p. 91).</p>
</div>
<p class="texte"><span class="paranumber">5</span>La convergence des dérivations devient une condition absolument nécessaire dans une approche intégrant une exigence de <em>good design</em>. Produire des représentations d’interface non lisibles constituerait un manquement grave à cette exigence et irait directement à l’encontre de la thèse minimaliste forte. Je reprends ici la formulation la plus récente de cette thèse, donnée dans <em>OPh</em> :</p>
<table class="example">
<tr>
<td>(1)</td>
<td><strong>Thèse minimaliste forte (</strong><em>Strong Minimalist Thesis</em>, SMT)</td>
</tr>
<tr>
<td> </td>
<td>Le langage est une solution optimale aux conditions de lisibilité que doit satisfaire la Faculté de Langage ; en d’autres termes, le langage est une façon optimale de relier le son et la signification, ces notions recevant un sens technique dans les termes des systèmes d’interface qui interviennent dans l’emploi et l’interprétation des expressions générées par un I-langage. </td>
</tr>
<tr>
<td> </td>
<td>(<em>OPh</em>, p. 135)</td>
</tr>
</table>
<p class="texte"><span class="paranumber">6</span>Dans les termes de (1), le langage n’est pas seulement un moyen de relier du son et de la signification en produisant des représentations lisibles aux deux interfaces, c’est aussi un moyen <em>optimal</em> de construire cette relation. Un I-langage n’inclut que les mécanismes minimaux et minimalement nécessaires à la computation de représentations accessibles aux systèmes d’interface externes. C’est à la lumière de cette hypothèse qu’il convient de comprendre et d’interpréter plusieurs des traits constitutifs de l’architecture et de la computation minimalistes. La stratégie de recherche poursuivie par Chomsky (dans <em>MI</em> en particulier) consiste en effet à identifier des propriétés que la Faculté de Langage devrait avoir ou au contraire ne pas avoir dans l’hypothèse où la SMT est vraie, à chercher si des « imperfections » existent, qui pourraient aller à l’encontre de la SMT, à vérifier si ces imperfections sont réelles ou seulement apparentes.</p>
<p class="texte"><span class="paranumber">7</span>Une computation optimale doit tout d’abord observer la Condition d’inclusion :</p>
<table class="example">
<tr>
<td>(2)</td>
<td><strong>Condition d’inclusion</strong> (<em>Inclusiveness Condition</em>)</td>
</tr>
<tr>
<td> </td>
<td>Aucun trait nouveau n’est introduit par le système computationnel C<sub>HL </sub>au cours de la dérivation. </td>
</tr>
<tr>
<td> </td>
<td>(<em>MI</em>, p. 113 ; <em>C&amp;T</em>, p. 228 ; <em>DbP</em>, p. 2)</td>
</tr>
</table>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">4</span> Le mot trait en (2) a le sens très général de « propriété spécifique associée à un objet », et non <a href="#ftn4">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">8</span>C<sub>HL</sub> (abréviation de <em>Computational System of Human Language</em>) désigne le système computationnel qui effectue l’application d’un échantillon lexical sur une paire (PHON, SEM).<a class="footnotecall" id="bodyftn4" href="#ftn4">4</a> L’idée essentielle est que les objets qui correspondent à l’output de la computation, les représentations SEM en particulier, doivent être exclusivement constitués d’éléments déjà présents dans les items lexicaux définissant la sélection initiale. Le rôle de la syntaxe se limite donc à disposer les items lexicaux les uns par rapport aux autres, elle ne peut créer d’objets nouveaux. La condition (2), en posant que la projection de la structure s’effectue exclusivement à partir du Lexique, exclut en effet l’introduction, en cours de dérivation, d’objets ou de propriétés qui ne peuvent être caractérisés comme inclus dans l’échantillon lexical initial. Elle garantit ainsi que l’inventaire des primitives syntaxiques est réduit au minimum. (2) peut donc être vue comme l’une des conditions qui contribuent de façon décisive au <em>design</em> optimal, visant à ne produire que des computations élégantes, minimales et efficaces. Observons que la formulation de (2) n’a de sens que parce que le Lexique et le système computationnel sont posés comme deux entités séparées et que le premier alimente le second.</p>
</div>
<p class="texte"><span class="paranumber">9</span>Or l’adoption de (2) comme principe gouvernant les computations a des conséquences d’une portée considérable. Elle a en particulier pour effet d’éliminer une panoplie d’outils descriptifs abusivement utilisés dans les périodes précédentes.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">5</span> Je reprends l’usage introduit par Lisa Selkirk, consistant à noter les barres au moyen d’apostrophe <a href="#ftn5">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">10</span>(i) Dans <em>LGB</em>, les catégories syntaxiques, en particulier celles qui sont créées en cours de dérivation (par la projection d’un spécifieur ou par l’adjonction à une tête ou à une projection maximale) sont, comme le requiert la théorie X-barre, spécifiées pour un certain nombre de barres, indiquant leur degré de complexité (le système manipule ainsi des catégories X°, X’, X”…).<a class="footnotecall" id="bodyftn5" href="#ftn5">5</a> Les labels catégoriels étiquetant les nœuds préterminaux, distincts des traits associés aux items lexicaux qui y sont insérés, introduisent aussi des éléments nouveaux dans les représentations. Ces facilités, qui ne sont pas purement notationnelles, ne sont plus disponibles si (2) est adopté.</p>
</div>
<p class="texte"><span class="paranumber">11</span>(ii) Pour capturer la propriété de dislocation des langues naturelles – le fait que les constituants syntaxiques sont assez généralement prononcés dans des positions différentes de celles où ils sont interprétés (voir chapitre VII) –, le modèle des Principes et Paramètres reprenait l’hypothèse que le déplacement existe et posait que tout élément déplacé laisse une trace dans la position d’origine, formant une chaîne (un objet discontinu) avec le terme déplacé. Or les traces ne font pas partie de l’échantillon lexical initial, ce sont des éléments nuls spécifiques, créés en cours de dérivation, des formants grammaticaux indépendants avec leurs traits et leurs conditions de légitimation propres. L’intégration de tels objets au dispositif va directement à l’encontre de (2).</p>
<p class="texte"><span class="paranumber">12</span>(iii) La théorie du liage, définie dans <em>LGB</em>, reposait sur le mécanisme des indices et sur la notion de coïndexation, les principes A, B et C de cette théorie n’étant rien d’autre que des contraintes sur la bonne formation des relations de coïndexation. (2) exclut absolument l’introduction d’indices, au cours de la computation, tout comme celle d’opérateurs λ (voir <em>MI</em>, p. 114).</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">6</span> La Théorie Standard Étendue intégrait un autre principe que l’on peut, comme (2), interpréter comme <a href="#ftn6">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">13</span>L’adoption de la Condition d’inclusion impose donc de réviser radicalement certains composants essentiels du modèle précédent. Il convient en effet de formuler une théorie nouvelle de la structure en constituants, distincte de la théorie X-barre, n’ayant recours ni aux catégories syntagmatiques ni aux niveaux barre, une théorie nouvelle des relations d’anaphore et de coréférence, se dispensant de la notion technique de liage fondée sur la coïndexation, une théorie nouvelle du mouvement, faisant l’économie des traces. Or sur ces trois points fondamentaux, des réponses ont déjà été apportées qui, bien que loin d’être définitives, confirment que la réalisation de cette partie du Programme Minimaliste est envisageable. Une approche nouvelle de la structure syntagmatique est développée dans <em>BPS</em> et <em>C&amp;T </em>(voir IV et V). Le module du liage est en cours de révision (voir X). Le minimalisme développe une théorie du « mouvement par copie », en fait seule option envisageable si l’on adopte la Condition d’inclusion (voir VII).<a class="footnotecall" id="bodyftn6" href="#ftn6">6</a></p>
</div>
<p class="texte"><span class="paranumber">14</span>Une autre condition qui devrait être observée si la SMT est correcte et si le langage est optimalement configuré est la Condition d’interprétabilité.</p>
<table class="example">
<tr>
<td>(3)</td>
<td><strong>Condition d’interprétabilité</strong> (<em>Interpretability Condition</em>)</td>
</tr>
<tr>
<td> </td>
<td>Les items lexicaux n’ont pas de traits autres que ceux qui sont interprétés à l’interface, propriétés du son et de la signification. </td>
</tr>
<tr>
<td> </td>
<td>(<em>MI</em>, p. 113)</td>
</tr>
</table>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">7</span> Le trait de Cas structural sur les noms appartient à cette classe. La fonction du Cas est purement <a href="#ftn7">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">15</span>Dans les termes de (3), la Faculté de Langage opère exclusivement avec des traits qui sont interprétables aux interfaces. « Trait » doit être ici interprété en un sens restreint et désigne une dimension morphologique, syntaxique ou sémantique d’une catégorie à laquelle les règles et les principes de la grammaire peuvent référer. Une entité nominale est ainsi spécifiée pour un trait de nombre, une forme verbale fléchie porte un trait de personne… Faisons abstraction des traits intervenant dans les représentations phonologiques et concentrons-nous sur les traits <em>sémantiquement</em> interprétables, c’est-à-dire sur ceux qui interagissent avec le système C-I et participent directement à la construction du sens. On sait qu’une dimension essentielle dans le <em>design</em> optimal est la nécessité de satisfaire à l’exigence de lisibilité. Les traits qui feraient obstacle à cette exigence ne peuvent être tolérés dans un système bien configuré. Or nous verrons que le système computationnel ne manipule pas que des traits sémantiquement interprétables. Il contient aussi des traits ininterprétables, c’est-à-dire des traits dont la présence sur un item lexical, si elle peut parfois être justifiée par des considérations morphosyntaxiques, ne contribue aucunement à la construction du sens de cette unité et de l’énoncé qui la contient.<a class="footnotecall" id="bodyftn7" href="#ftn7">7</a> Ces traits représentent à première vue une imperfection. Dans la conception minimaliste, la tâche principale dévolue aux opérations syntaxiques est précisément d’éliminer les traits ininterprétables, avant que n’interviennent les opérations de l’interface sémantique. Plus précisément, ce sont les traits morphosyntaxiques ininterprétables qui guident les dérivations syntaxiques et donnent lieu à l’établissement de relations de dépendance. Il y a plusieurs façons d’implémenter cette idée, sur lesquelles je reviendrai en détail aux chapitres III, VI et VII. Retenons pour l’instant la proposition suivante, dans la formulation simplifiée que lui a donnée Adger (2003) :</p>
</div>
<table class="example">
<tr>
<td>(4)</td>
<td><strong>Exigence de vérification</strong> (<em>Checking Requirement</em>)</td>
</tr>
<tr>
<td> </td>
<td>Les traits ininterprétables doivent être vérifiés. Une fois vérifiés, ils peuvent être effacés.</td>
</tr>
</table>
<p class="texte"><span class="paranumber">16</span>En résumé, la Condition d’interprétabilité n’exclut pas que le système computationnel ait recours à des traits ininterprétables, elle impose seulement que ces traits aient été éliminés lorsque la dérivation atteint les niveaux d’interface, qui ne peuvent contenir que des traits interprétables à chacun de ces niveaux.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">8</span> Lasnik et Uriagereka (2005, p. 8) observent que les étiquettes <em>Deep structure </em>et <em>Surface structure</em> <a href="#ftn8">(...)</a></li>
<li><span class="num">9</span> Si la conclusion concernant la structure S paraît légitime, le sort réservé à la structure D paraît <a href="#ftn9">(...)</a></li>
<li><span class="num">10</span> Notons que le Principe de l’interprétation intégrale, principe de bonne formation sur les représent <a href="#ftn10">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">17</span>Une dernière dimension susceptible de participer au <em>design</em> optimal n’est pas l’élégance computationnelle ou la lisibilité des niveaux d’interface, mais l’intégration ou non-intégration au dispositif d’autres niveaux de représentation, en particulier la structure D (<em>D-structure</em>) et la structure S (<em>S-structure</em>) qui figuraient dans l’architecture des versions antérieures du modèle.<a class="footnotecall" id="bodyftn8" href="#ftn8">8</a> Dans la théorie des Principes et Paramètres, la structure D est une représentation pure des relations de dépendance lexicale et de sous-catégorisation entre constituants de l’énoncé. Structure arborescente préconstruite, lieu des opérations d’insertion lexicale, elle peut être vue comme le reflet structural des propriétés sélectionnelles des éléments lexicaux. La structure S est une représentation des relations de dépendance hiérarchique et linéaire entre les éléments tête et les syntagmes, après que les opérations de déplacement et d’effacement se sont appliquées. Formé par applications successives de Déplacer α à partir de la structure D, c’est en réalité un niveau de représentation plus abstrait que cette dernière, puisqu’il contient une classe d’éléments nuls, les traces, absents des représentations de structure D. C’est également le niveau qui, définissant l’input des règles dérivant la représentation LF, contient toute l’information nécessaire à la représentation des propriétés sémantiques et interprétatives de l’énoncé. C’est enfin le niveau servant d’entrée aux règles attribuant une forme phonique aux énoncés effectivement produits. On se souvient que, dans une perspective minimaliste, le dispositif ne doit inclure que des mécanismes et des outils virtuellement nécessaires du point de vue conceptuel. Il s’agit donc de rechercher si les phénomènes qui, dans le modèle antérieur, avaient conduit à stipuler la présence dans le dispositif de tel ou tel composant ou de tel ou tel niveau peuvent être dérivés en suivant au plus près la ligne fixée par la SMT. Or si les niveaux de représentation LF et PF tirent leur réalité et leur légitimité du fait qu’ils se trouvent en relation d’interface avec d’autres capacités cognitives et ne peuvent de ce fait être éliminés, il n’en va pas de même pour la structure D et la structure S. La structure S est en effet un niveau interne à la dérivation, dont la motivation est elle-même purement interne au modèle. Selon Chomsky, la structure D n’est pas non plus en relation d’interface avec un autre système.<a class="footnotecall" id="bodyftn9" href="#ftn9">9</a> Il conclut :<a class="footnotecall" id="bodyftn10" href="#ftn10">10</a></p>
</div>
<table class="example">
<tr>
<td>(5)</td>
<td> Les seuls niveaux de représentation linguistiquement pertinents sont les niveaux d’interface. (<em>MI</em>, p. 113)</td>
</tr>
</table>
<p class="texte"><span class="paranumber">18</span>La présence dans le dispositif des structures D et S aux côtés de LF et de PF conduisait à distinguer plusieurs cycles dérivationnels indépendants, celui qui correspond à la syntaxe explicite (<em>overt syntax</em>), celui qui correspond à la syntaxe silencieuse (<em>covert syntax</em>) et coïncide avec le composant LF, enfin le cycle PF. Ces cycles couvraient pour l’essentiel le même terrain, ce qui créait une redondance considérable. Un système ne faisant pas ce type de distinction et postulant un cycle unique est préférable. L’élimination des niveaux D et S est un grand pas dans cette direction et constitue donc un objectif désirable.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">11</span> Dans les constructions passives et dans les constructions à montée, l’expression nominale se déplac <a href="#ftn11">(...)</a></li>
<li><span class="num">12</span> Sur la reconstruction, voir en particulier Fox (1999, 2000) et X.3.</li>
<li><span class="num">13</span> Ce qui revient à dire que ce sont les têtes de chaîne qui sont prononcées. Cette hypothèse est sans <a href="#ftn13">(...)</a></li>
<li><span class="num">14</span> Voir aussi sur ce point le chapitre II de Hornstein, Nunes et Grohmann (2005). </li>
</ul>
<p class="texte"><span class="paranumber">19</span>Mais cette élimination a des conséquences multiples qu’il convient maintenant d’affronter. Celles induites par la disparition de la structure S apparaissent immédiatement. La motivation initiale appuyant l’existence d’un niveau de représentation distingué est précisément que des principes et des contraintes opèrent à ce niveau. Le Filtre sur le Cas, par exemple, qui ne pouvait s’appliquer au niveau de la structure D (avant les déplacements)<a class="footnotecall" id="bodyftn11" href="#ftn11">11</a>, ni après la structure S (parce que le Cas abstrait est morphologiquement réalisé dans certaines langues), était supposé opérer au niveau S<em>.</em> Un raisonnement analogue valait pour le Principe C de la théorie du liage. La stratégie poursuivie par Chomsky consiste à montrer que, moyennant certaines hypothèses, rien ne s’oppose à ce que ces principes opèrent uniformément sur les représentations de LF. Le Filtre sur le Cas peut être reformulé comme un cas particulier du Principe de l’interprétation intégrale ou de la Condition d’interprétabilité (3). L’idée que le Cas structural est assigné dérivationnellement est abandonnée. Les items nominaux sont introduits dans les dérivations déjà porteurs d’un trait de Cas (qui peut être morphologiquement manifesté ou ne pas l’être). Comme n’importe quel autre trait non interprétable, ce trait doit être soumis à une procédure de vérification (<em>checking</em>) pour être éliminé – voir (4). La vérification passe dans ce cas par la mise en relation du trait avec la catégorie fonctionnelle qui légitime chaque Cas particulier : le T fini légitime le trait [nominatif], le v transitif le trait [accusatif]… Quant au Principe C, une bonne partie de sa couverture empirique peut être dérivée si l’on raisonne dans les termes de la théorie du mouvement par copie, qui ouvre la voie à une analyse cohérente et séduisante des phénomènes de reconstruction.<a class="footnotecall" id="bodyftn12" href="#ftn12">12</a> Un avantage immédiat de cette théorie est qu’elle rend disponibles les éléments requis pour l’interprétation à l’interface C-I, les copies précisément, tout en permettant une dérivation maximalement simple de l’interface SM : dans le cas général, toutes les copies sont effacées à ce niveau, à l’exception de la plus haute.<a class="footnotecall" id="bodyftn13" href="#ftn13">13</a> Cette discussion sera reprise dans les chapitres suivants. Mais elle permet de comprendre comment les prédictions empiriques associées à l’hypothèse d’un niveau S sont dérivables dans un système qui n’intègre pas cette hypothèse.<a class="footnotecall" id="bodyftn14" href="#ftn14">14</a></p>
</div>
<p class="texte"><span class="paranumber">20</span>Avant de clore cette discussion, il est nécessaire de souligner une asymétrie majeure entre les deux niveaux d’interface, LF et PF. Dans <em>MI</em>, Chomsky prend soin de préciser que la Condition d’inclusion et la Condition d’interprétabilité ne valent que pour la syntaxe étroite (<em>narrow syntax</em>, la syntaxe proprement dite), c’est-à-dire pour le trajet dérivationnel qui à un échantillon lexical fait correspondre une représentation de LF. Le composant phonologique qui prend comme input des objets syntaxiques construits par le système computationnel et les convertit en représentations de PF contrevient systématiquement à ces conditions. La Condition d’inclusion (2) est violée par les opérations qui introduisent des éléments nouveaux comme la structure prosodique. Cette condition et la Condition d’interprétabilité (4) le sont aussi par le décalage qui existe entre les propriétés phonologiques des items lexicaux et les représentations phonétiques (des combinaisons) de ces éléments (voir <em>MI</em>, p. 118). Il n’est même pas certain que les traits phonologiques des items lexicaux apparaissent au niveau PF<em>.</em> On pourrait avoir affaire à deux vocabulaires disjoints, phonologique à l’input, phonétique à l’output. Il s’agit bien là d’une imperfection irréductible. Ces observations ne signifient pas que la phonologie ne fait pas partie de l’agenda minimaliste. Le but premier de l’entreprise n’est-il pas de déterminer la nature du lien entre le système C-I et le système SM ? Ce projet ne peut contourner la phonologie. La question est plutôt de déterminer dans quelle mesure les règles phonologiques constituent une solution optimale au problème de la relation entre les objets de la syntaxe étroite et le système SM, l’optimalité de la solution se mesurant à l’aune de l’efficacité computationnelle. La conclusion est que certains aspects de la phonologie ne semblent pas être gouvernés par les principes minimalistes, un thème récurrent dans les écrits de Chomsky. En fait, ces principes ne concernent que la syntaxe étroite, c’est-à-dire la « computation de LF ». La thèse minimaliste forte doit donc être reformulée comme suit :</p>
<table class="example">
<tr>
<td>(6)</td>
<td><strong>Thèse minimaliste forte </strong></td>
</tr>
<tr>
<td> </td>
<td>Le langage est une solution optimale aux conditions de lisibilité que doit satisfaire LF.</td>
</tr>
</table>
<h1 class="texte"><a href="#tocfrom1n2" id="tocto1n2">2. Dérivations/représentations</a></h1>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">15</span> La notion de chaîne est discutée en VII.4.4.</li>
<li><span class="num">16</span> La condition excluant que les deux arguments d’un verbe transitif, l’argument externe et l’argument <a href="#ftn16">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">21</span>Les développements qui précèdent montrent sans ambiguïté que le Programme Minimaliste est un modèle dérivationnel : les divers processus intervenant dans la computation sont crucialement ordonnés les uns par rapport aux autres. Afin de préciser ce point fondamental, examinons les différentes options qui peuvent être envisagées a priori. On peut adopter une approche fortement dérivationnelle, n’intégrant pas de niveau de représentation à partir duquel l’information est transmise aux systèmes d’interface, mais dans laquelle les systèmes de performance (ceux qui exploitent les objets PHON et SEM produits par la dérivation) ont un accès direct à la computation – c’est la position défendue par Epstein, Groat, Kawashima et Kitahara (1998). On peut au contraire raisonner dans les termes d’une approche purement représentationnelle, n’intégrant pas de notion de dérivation et n’opérant qu’avec des conditions s’appliquant aux représentations d’interface LF et PF. C’est le cas du modèle proposé par Brody (1995), où la formation de chaînes (c’est-à-dire d’objets purement représentationnels, impliquant potentiellement plusieurs positions) se substitue au mouvement (et fait l’économie de la vérification de traits par mouvement, voir 4.2).<a class="footnotecall" id="bodyftn15" href="#ftn15">15</a> Brody (2002, 2003) observe qu’une théorie qui recourt à la fois aux chaînes et au mouvement est conceptuellement redondante. Il ajoute qu’alors qu’une approche représentationnelle peut être strictement non dérivationnelle, une approche dérivationnelle est généralement en partie représentationnelle, ne serait-ce que parce qu’elle intègre le concept de structure syntaxique. Une approche « faiblement représentationnelle », quant à elle, reposerait sur un dispositif comprenant à la fois des opérations cycliques de construction de la structure et des conditions d’output évaluant la convergence de chacun des niveaux d’interface, ce qui suppose que ces niveaux existent. Or c’est clairement cette dernière option qui est retenue dans le Programme Minimaliste. Ce dernier autorise l’application de règles post-cycliques affectant tout ou partie des niveaux d’interface : « effacement de la queue d’une chaîne, imposition de la structure métrique, détermination de l’ellipse et de la portée » (<em>MI</em>, p. 98), ce qui suppose que la dérivation a accès au matériel déjà assemblé. D’autres conditions d’output sont nécessaires pour exclure certaines structures mal formées produites par le système computationnel sans violation d’aucun principe dérivationnel. Chomsky appelle ces dernières <em>bare output conditions </em>: <em>output</em> parce que ce sont des conditions qui s’appliquent aux niveaux d’interface dans une approche dérivationnelle, <em>bare</em> parce qu’elles se distinguent des filtres et des contraintes qui font partie du système computationnel lui-même (voir <em>MI</em>, note 16).<a class="footnotecall" id="bodyftn16" href="#ftn16">16</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">17</span> On peut imaginer la situation suivante : une information est disponible à un point de la dérivation <a href="#ftn17">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">22</span>L’histoire récente de la syntaxe formelle est marquée par cette opposition entre approche dérivationnelle et approche représentationnelle. Les théories que l’on regroupe artificiellement sous l’étiquette de grammaires d’unification n’intègrent aucune notion de dérivation et éliminent le mouvement de l’inventaire des opérations possibles. Le minimalisme chomskyen accentue au contraire le caractère dérivationnel des modèles génératifs précédents. Une approche représentationnelle n’est cependant pas incompatible avec une posture minimaliste. De fait, Brody situe explicitement son approche représentationnelle dans la mouvance minimaliste. Chomsky évoque, sans les développer, quelques pistes de recherche qui permettraient de décider. Dans une approche dérivationnelle, on s’attend à ce que des principes de computation efficace se révèlent pertinents, que les opérations soient strictement locales, qu’aucune ne soit superflue ou sans effet.<a class="footnotecall" id="bodyftn17" href="#ftn17">17</a> Poser que les expressions linguistiques complexes sont formées dérivationnellement à partir d’une collection d’items lexicaux a un avantage immédiat. Cela permet d’intégrer au dispositif l’idée que la compositionnalité est une propriété fondamentale des langues naturelles.</p>
</div>
<p class="texte"><span class="paranumber">23</span>On peut observer en conclusion que les notions de dérivation et de représentation n’ont pas le même statut. La première est une notion technique précise : c’est une suite d’opérations transformationnelles, parmi lesquelles le « mouvement » (ou « déplacement ») occupe une position privilégiée, définissant une famille d’indicateurs syntagmatiques (<em>phrase markers</em>) partiellement ordonnés. Au contraire, le statut théorique de la notion de représentation est relativement imprécis et son usage ambigu. Au sens étroit, « représentation » signifie « indicateur syntagmatique à une interface donnée ». Mais cela ne nous dit pas quelle est la nature de cette représentation. Il est essentiel de déterminer si un indicateur syntagmatique unique peut en général coder une dérivation grammaticale complète. On sait qu’au début des années soixante-dix, Chomsky dans <em>CoT</em> et Fiengo (1977) ont apporté une réponse positive à cette question, en admettant que les indicateurs syntagmatiques pouvaient contenir des traces. Moyennant cette extension, la famille d’indicateurs syntagmatiques définie par une dérivation donnée peut être réduite à un indicateur unique. C’est là un résultat empirique de grande portée, qui demeure accessible dans la théorie minimaliste du mouvement par copie. Mais la question d’une redondance éventuelle entre le mouvement et la formation de chaînes reste posée.</p>
<p class="texte"><span class="paranumber">24</span>Les sections qui suivent visent à présenter brièvement chacun des composants du dispositif minimaliste : le Lexique, la numération / l’échantillon lexical, le système computationnel, l’épellation / le transfert, et les niveaux d’interface, en explicitant chemin faisant les conséquences architecturales de l’élimination des niveaux D et S.</p>
<h1 class="texte"><a href="#tocfrom1n3" id="tocto1n3">3. Le Lexique et la sélection lexicale</a></h1>
<p class="texte"><span class="paranumber">25</span>Le langage étant composé d’expressions qui associent du son et de la signification, pouvant être décrites comme des paires (π, λ) ou (PHON, SEM), on s’attend à ce que la Grammaire Universelle rende disponibles les éléments suivants : (i) un ensemble F de traits phonologiques, sémantiques et grammaticaux, unique matériel entrant dans la constitution des items lexicaux, (ii) une procédure permettant d’assembler les traits pour former des items lexicaux, et (iii) un ensemble restreint d’opérations qui constituent le C<sub>HL</sub>, le système computationnel spécifique au langage humain qui a accès à un sous-ensemble de F pour générer des objets syntaxiques. Considérons plus spécifiquement (i) et (ii).</p>
<p class="texte"><span class="paranumber">26</span>Une langue L applique F sur un ensemble particulier d’expressions EXP en suivant la procédure détaillée en (7) :</p>
<table class="example">
<tr>
<td>(7)</td>
<td>(a) </td>
<td>Sélectionner [F] dans l’ensemble universel de traits F.</td>
</tr>
<tr>
<td> </td>
<td>(b) </td>
<td>Sélectionner LEX, en assemblant des traits de [F].</td>
</tr>
<tr>
<td> </td>
<td>(c) </td>
<td>Sélectionner LA (<em>lexical array</em> « échantillon lexical ») dans LEX.</td>
</tr>
<tr>
<td> </td>
<td>(d) </td>
<td>Appliquer LA sur EXP (« expression ») sans recours à [F] pour la syntaxe étroite.</td>
</tr>
<tr>
<td> </td>
<td> </td>
<td>(<em>MI</em>, p. 101)</td>
</tr>
</table>
<p class="texte"><span class="paranumber">27</span>Prises ensemble, ces quatre opérations permettent de passer de l’ensemble universel de traits F aux expressions spécifiques à une langue particulière. Le processus s’effectue en deux temps : les opérations (7a) et (7b) spécifient à quelle langue L on a affaire, en construisant son lexique, c’est-à-dire en formant des items lexicaux par assemblage des traits sélectionnés ; (7c) et (7d) entrent ensuite en jeu pour dériver les expressions particulières de L. Seuls les éléments de LEX peuvent figurer dans les expressions de L. Mettant en avant la nécessité de réduire la complexité opératoire, considération pertinente si on se place dans la perspective d’un <em>design</em> optimal, Chomsky fait l’hypothèse que la sélection de [F] à partir de F est opérée en une fois, sans aucun accès ultérieur à F, tout comme l’assemblage de LEX à partir de [F]. En d’autres termes, la syntaxe étroite (c’est-à-dire la syntaxe en tant qu’elle exclut la branche PF de la grammaire) n’a pas accès à [F], mais seulement à LEX et aux traits des items lexicaux. Chomsky précise que les traits flottants, à l’état libre, qui ne sont pas inclus dans un paquet de traits, ne sont pas accessibles à la computation. Cette dernière n’a donc pas accès aux traits directement.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">18</span> Le concept de numération, tel qu’il est introduit par Chomsky, rappelle celui de « multi-ensemble » <a href="#ftn18">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">28</span>L’introduction d’une autre notion, LA (<em>lexical array</em> « échantillon lexical »), procède de la même exigence minimaliste : celle d’accroître l’efficacité dérivationnelle et de limiter au maximum la « complexité opératoire » ou la « charge computationnelle ». LA désigne simplement la collection d’items lexicaux (éléments fonctionnels inclus), sélectionnés dans LEX, qui sert de base à la construction d’une expression de L. L’idée est que, dans la construction de cette expression, une phrase complexe par exemple, la dérivation effectue une sélection unique d’items lexicaux à partir de LEX – LA précisément – et, qu’une fois cette sélection opérée, elle n’a plus accès qu’à LA, non au lexique tout entier. Si c’était le cas, la complexité computationnelle serait accrue, avec des conséquences négatives évidentes touchant le <em>design</em> général du système. Dans <em>C&amp;T</em>, Chomsky avait introduit une notion différente, celle de <em>numeration</em>. La numération est une collection d’items lexicaux indicés (<em>C&amp;T</em>, p. 225). Comme LA, elle consiste en un sous-ensemble des items lexicaux qui définissent LEX. Mais, dans la définition de la numération donnée dans <em>C&amp;T</em>, chaque item lexical est doté d’un indice souscrit, indiquant le nombre de fois où il est sélectionné, c’est-à-dire le nombre de ses occurrences. Chaque fois que la dérivation a accès à la numération, elle sélectionne une occurrence unique de l’item et l’indice de ce dernier est réduit d’une unité. La dérivation s’arrête quand la numération est épuisée, c’est-à-dire quand tous les indices sont égaux à 0. Bref, l’intention sous-jacente à la notion de numération est la nécessité de garantir qu’un même item puisse être sélectionné plusieurs fois au cours d’une dérivation et donc apparaître dans plusieurs positions de l’énoncé résultant. Dans <em>DbP</em> (p. 11), Chomsky précise la relation existant entre échantillon lexical et numération : un échantillon lexical LA est une numération N si certains items lexicaux sont sélectionnés plus d’une fois. C’est donc à l’étape (7c) qu’est définie la numération.<a class="footnotecall" id="bodyftn18" href="#ftn18">18</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">19</span> Dans ce qui suit, j’utiliserai indifféremment les étiquettes « numération » et « échantillon lexica <a href="#ftn19">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">29</span>Si elle est plus simple, la notion de LA n’est pas dans la meilleure position pour rendre compte des situations d’occurrences multiples du même élément. Une possibilité serait d’admettre que l’opération de sélection peut prélever plusieurs occurrences du même item lexical dans LEX. Mais, comme l’observe Atkinson (2007), cette suggestion est illégitime si LA est définie comme un ensemble. L’ensemble contenant deux occurrences de <em>livre</em> est en effet strictement identique à celui qui n’en contient qu’une. Une autre option envisageable est que la sélection d’un item n’implique pas nécessairement qu’il soit retiré de LA. Il peut être retiré, mais il peut aussi être maintenu et réutilisé après la première sélection. Je ne poursuivrai pas la discussion de ce point. Il n’est pas certain que le recours à la notion de LA (aménagée) plutôt qu’à celle de numération ait des conséquences empiriques, condition nécessaire pour que la question puisse être tranchée.<a class="footnotecall" id="bodyftn19" href="#ftn19">19</a></p>
</div>
<h1 class="texte"><a href="#tocfrom1n4" id="tocto1n4">4. <em>Merge</em> et <em>Move</em></a></h1>
<p class="texte"><span class="paranumber">30</span>Outre <em>Select</em> (Sélectionner), qui intervient en (7), C<sub>HL</sub> inclut d’autres opérations. Ce sont <em>Merge</em> (Assembler), <em>Agree</em> (Accorder), <em>Move</em> (Déplacer) et <em>Spell-Out</em> (Épeler). J’introduirai ici brièvement ces opérations, à l’exception d’<em>Agree</em> qui sera présenté au chapitre VI.</p>
<h2 class="texte"><a href="#tocfrom2n1" id="tocto2n1">4.1. <em>Merge</em></a></h2>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">20</span> <em>Merge</em> est souvent traduit par « fusionner » en français. « Assembler » me paraît préférable. « Comb <a href="#ftn20">(...)</a></li>
<li><span class="num">21</span> Postal (2003) observe que la référence aux opérations combinatoires installe subrepticement la conc <a href="#ftn21">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">31</span>Le minimalisme hérite des recherches antérieures l’idée que la propriété d’infinité hiérarchique discrète est une caractéristique définitoire des langues naturelles et que, pour la représenter de façon appropriée, la grammaire doit se doter d’une procédure récursive. Une phrase est considérée comme résultant d’une computation, organisant les items lexicaux qu’elle contient en une structure hiérarchisée, dérivée par application réitérée d’une opération de construction de la structure. Dans le Programme Minimaliste, cette opération est désignée sous l’étiquette <em>Merge</em>.<a class="footnotecall" id="bodyftn20" href="#ftn20">20</a><em>Merge</em> prend comme input deux objets syntaxiques et les combine pour former un objet complexe plus étendu.<a class="footnotecall" id="bodyftn21" href="#ftn21">21</a> Nul doute que la façon la plus simple de produire un objet unique nouveau à partir de deux objets existants est de constituer un ensemble. C’est le sens de la caractérisation de <em>Merge</em> donnée en (8).</p>
</div>
<table class="example">
<tr>
<td>(8)</td>
<td>Merge (α, ß) → K = {α, ß}</td>
</tr>
</table>
<p class="texte"><span class="paranumber">32</span>Selon Chomsky, le <em>Merge</em> non borné (ou toute opération équivalente) est « nécessaire » dans la modélisation d’un système illustrant la propriété d’infinité hiérarchique discrète des langues naturelles (c’est-à-dire le fait que les mots d’une langue se combinent pour former des constituants et des phrases et qu’il n’existe pas de limite sur le nombre de constituants qui peuvent être ainsi assemblés et pas de limite sur la longueur des phrases).</p>
<p class="texte"><span class="paranumber">33</span>Cette présentation préliminaire laisse plusieurs questions sans réponse : celle de la binarité de <em>Merge </em>(<em>Merge</em>, pour opérer, doit assembler deux objets syntaxiques au moins ; peut-il assembler plus de deux objets ?), celle du « label » de l’objet résultant, celle de la linéarisation des objets assemblés. Ces questions sont reprises dans les chapitres IV et V.</p>
<h2 class="texte"><a href="#tocfrom2n2" id="tocto2n2">4.2. <em>Move</em></a></h2>
<p class="texte"><span class="paranumber">34</span>La deuxième opération de l’inventaire est connue depuis longtemps, puisqu’il s’agit de <em>Move</em> « Déplacer ». Mais sa caractérisation a considérablement évolué depuis la définition de <em>Move α</em> dans le modèle des Principes et Paramètres. Dans <em>C&amp;T </em>et <em>MI</em>, <em>Move</em> est construit comme un processus computationnellement complexe qui combine plusieurs sous-composants, ce qui exclut de considérer le déplacement comme une opération élémentaire. Il inclut en particulier une instance spécifique de <em>Merge</em> dans laquelle l’item lexical inséré n’est pas prélevé directement dans la numération, mais correspond à la copie d’un objet syntaxique déjà présent dans la structure construite au préalable. Dans ses premières caractérisations minimalistes, <em>Move </em>combine plusieurs opérations élémentaires.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">22</span> La notion de c-commande est définie en (13), chapitre IV.</li>
<li><span class="num">23</span> C’est de façon impropre que l’on parle d’effacement de la copie, puisqu’il s’agit en réalité de l’e <a href="#ftn23">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">35</span>(i)<em> Copy </em>: Étant donné une tête fonctionnelle X dotée d’un trait ininterprétable F, un objet syntaxique doté du même trait F est sélectionné dans le domaine de c-commande de X et copié.<a class="footnotecall" id="bodyftn22" href="#ftn22">22</a><br />(ii) <em>Merge </em>copy : La copie de la cible est insérée dans la position spécifieur de X.<br />(iii) <em>Delete </em>copy : La copie la plus basse est effacée par une opération intervenant à l’interface PF.<a class="footnotecall" id="bodyftn23" href="#ftn23">23</a></p>
</div>
<p class="texte"><span class="paranumber">36</span>À ces trois opérations s’ajoute la nécessité de déterminer la taille du constituant déplacé, c’est-à-dire la quantité de matériel lexical qui « suit le mouvement » (c’est la question du <em>pied-piping</em>). Cette dernière condition fait que <em>Move</em> est non seulement plus complexe que chacun de ses composants, ce qui va de soi, mais aussi plus complexe que tous ses composants pris ensemble.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">24</span> Il est nécessaire de distinguer les situations où on a affaire à un ensemble d’occurrences du même <a href="#ftn24">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">37</span>On voit que dans ce dispositif, inauguré par <em>C&amp;T</em>, la référence au mouvement doit être comprise de façon purement métaphorique. Ce sont le <em>merger </em>de la copie dans le site d’arrivée et l’effacement de l’item initial qui produisent l’illusion du mouvement. Afin d’éviter de recourir à la métaphore du mouvement, Chomsky dans <em>MI</em> utilise le terme d’« occurrence » pour désigner les segments d’une chaîne de mouvement. <em>Move</em> crée (au moins) deux occurrences d’un même objet α, où chaque occurrence de α est (définie par) le contexte dans lequel α figure.<a class="footnotecall" id="bodyftn24" href="#ftn24">24</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">25</span> On admet provisoirement ici que le mouvement est la seule stratégie disponible permettant de légiti <a href="#ftn25">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">38</span>Une préoccupation constante du projet minimaliste est de fournir une justification indépendante pour l’application de chaque opération intervenant dans une dérivation. La question se pose aussi bien pour <em>Move </em>que pour <em>Merge. </em>Dans le cas de <em>Move</em>, l’idée est que, lorsqu’un élément se déplace, il se déplace pour une raison, condition dont on peut considérer qu’elle participe du <em>design</em> optimal. Cette préoccupation sous-tendait déjà l’analyse de plusieurs phénomènes dans le modèle précédent, l’assignation casuelle par exemple. Depuis l’introduction de la notion de Cas abstrait par Vergnaud (1977), on a en effet toujours supposé que la nécessité pour une expression nominale de satisfaire le Filtre sur le Cas était l’une des raisons imposant le déplacement de cette expression (voir note 11). Ainsi dans une construction à montée, l’argument externe de la proposition infinitive, thématiquement marqué par le prédicat non fini, ne peut demeurer dans la position de sujet grammatical de cette proposition. Ceci parce que ni le Temps non fini de la proposition infinitive ni le prédicat <em>sembler</em>, qui appartient à la classe des inaccusatifs, ne rendent disponible un Cas qui pourrait légitimer ce sujet. C’est ce qui explique l’agrammaticalité de (9b)/(9b’), où la position de sujet flexionnel de la proposition matrice, le spécifieur de TP, est occupée par l’explétif <em>il</em>, et la bonne formation de (9c)/(9c’), où <em>les étudiantes</em> a été déplacé dans cette position qui, étant associée à une tête Temps fini, est un site d’assignation du Cas nominatif.<a class="footnotecall" id="bodyftn25" href="#ftn25">25</a></p>
</div>
<table class="example">
<tr>
<td>(9)</td>
<td>a. </td>
<td>[<sub>TP</sub> __ T [<sub>VP</sub> semble [<sub>TP</sub> les étudiantes T parler le chinois couramment]]</td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>*Il semble les étudiantes parler le chinois couramment.</td>
</tr>
<tr>
<td> </td>
<td>b’. </td>
<td>[<sub>TP</sub> il T [<sub>VP </sub>semble [<sub>TP</sub> les étudiantes T parler le chinois couramment]]</td>
</tr>
<tr>
<td> </td>
<td>c. </td>
<td>Les étudiantes semblent parler le chinois couramment.</td>
</tr>
<tr>
<td> </td>
<td>c’. </td>
<td>[<sub>TP</sub> les étudiantes T [<sub>VP </sub>semblent [<sub>TP</sub><del>les étudiantes</del> T parler le chinois couramment]]</td>
</tr>
</table>
<p class="texte"><span class="paranumber">39</span>Le minimalisme raffine le traitement précédent sur deux points fondamentaux. D’une part, le mouvement est conçu comme une opération de « dernier recours » (<em>last resort</em>), c’est-à-dire comme une opération syntaxique qui n’est mise en œuvre que pour éviter un échec dérivationnel. Cette conception, qui se fonde sur des considérations d’économie, est en nette opposition avec celle qui était défendue dans le modèle des Principes et Paramètres, posant que le mouvement est libre, aussi longtemps qu’il n’est pas bloqué par un principe général. Si d’autre part, le mouvement se produit pour une raison, il faut identifier la dimension pertinente. Le minimalisme pose que le mouvement est guidé par une considération de nature morphosyntaxique, c’est-à-dire par l’exigence que tous les traits formels qui doivent l’être soient vérifiés. La caractérisation des traits pertinents a évolué. Dans le système mis en place dans <em>MI</em> et <em>DbP</em>, il s’agit des traits formels ininterprétables associés aux items fonctionnels et aux expressions lexicales, comme l’énonce l’exigence de vérification formulée en (4). Cette idée elle-même admet plusieurs implémentations, sur lesquelles je reviendrai en détail dans les chapitres III, VI et VII. Il apparaîtra que le trait de Cas n’est pas le seul impliqué dans la dérivation de (9) et que le trait responsable du déplacement de l’expression nominale est en réalité le trait [EPP] du Temps fini.</p>
<h2 class="texte"><a href="#tocfrom2n3" id="tocto2n3">4.3. La préférence de <em>Merge</em> sur <em>Move</em></a></h2>
<p class="texte"><span class="paranumber">40</span>La caractérisation des deux opérations <em>Merge</em> et <em>Move </em>qui vient d’être proposée ouvre la voie à la formulation d’un théorème, la Préférence de <em>Merge</em> sur <em>Move</em>, formulé dans <em>MI </em>comme en (10).</p>
<table class="example">
<tr>
<td>(10) </td>
<td><strong>Préférence de </strong><em><strong>Merge </strong></em><strong>sur </strong><em><strong>Move </strong></em>(Merge <em>over</em> Move <em>preference</em>, MOM)</td>
</tr>
<tr>
<td> </td>
<td><em>Merge</em> préempte <em>Move.</em></td>
</tr>
</table>
<p class="texte"><span class="paranumber">41</span>(10) énonce que si <em>Merge</em> et <em>Move </em>sont l’un et l’autre disponibles à un point de la dérivation, le système computationnel C<sub>HL</sub> donne systématiquement la préférence à <em>Merge</em>. C’est <em>Merge</em> qui doit être sélectionné dans les situations d’indétermination. Bien que la validité empirique et la solidité conceptuelle de (10) aient été aujourd’hui largement remises en cause, il est intéressant d’examiner en détail les considérations présentées à l’appui de cette préférence parce qu’elles constituent un exemple typique d’argumentation minimaliste. Il va de soi que la question de la préférence n’a de contenu que si les deux opérations <em>Merge</em> et <em>Move</em> sont posées comme distinctes. Comme nous le verrons, ce n’est plus le cas dans les approches minimalistes les plus récentes dans lesquelles la fonction de déplacement de <em>Move</em> est subsumée sous <em>Merge</em>.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">26</span> Les autres aspects biologiques du langage relèvent de la Faculté de Langage au sens large (FLB). Vo <a href="#ftn26">(...)</a></li>
<li><span class="num">27</span> C’est la position défendue dans <em>MI</em> et <em>DbP. </em>Dans <em>BEA</em>, <em>Move </em>n’est plus considéré comme une imperfecti <a href="#ftn27">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">42</span>Il convient de rappeler tout d’abord que, dans le minimalisme, l’objet premier de la recherche syntaxique est l’étude des propriétés du moteur génératif « optimal » qui effectue les computations syntaxiques, ce que Hauser, Chomsky et Fitch (2002) appellent la Faculté de Langage au sens étroit (FLN).<a class="footnotecall" id="bodyftn26" href="#ftn26">26</a> La caractéristique définitoire de ce moteur génératif est la propriété de récursivité, c’est-à-dire la possibilité de générer un ensemble infini d’expressions à partir d’un nombre fini d’éléments. Cette propriété n’est pas spécifique au langage, mais se retrouve dans d’autres domaines de la cognition et du comportement humains. Ce qui amène à se demander s’il existe une spécificité du langage, c’est-à-dire s’il existe des propriétés qu’il serait le seul à présenter. La réponse de Chomsky est que la récursivité dans le langage prend la forme de deux opérations de la syntaxe étroite, <em>Merge</em> et <em>Move</em> précisément. Or ces deux mécanismes n’ont pas le même statut. Alors que <em>Merge</em> semble être une caractéristique nécessaire de tous les systèmes combinatoires, <em>Move</em> ne semble pas avoir d’équivalent ailleurs, dans les langages formels construits et dans les systèmes symboliques. Il faut donc interpréter <em>Move </em>comme une opération spécifique au <em>design</em> des langues naturelles, éventuellement caractérisable comme une imperfection.<a class="footnotecall" id="bodyftn27" href="#ftn27">27</a></p>
</div>
<p class="texte"><span class="paranumber">43</span>Chomsky appuie cette distinction entre les deux opérations sur d’autres considérations. <em>Move</em> est une opération plus complexe computationnellement que <em>Merge. Move </em>combine plusieurs sous-composants – <em>Copy</em>, <em>Merge</em> et <em>Delete</em> – auxquels s’ajoute la nécessité de déterminer la taille du constituant déplacé. Admettons que les opérations simples soient préférées aux opérations complexes, parce qu’elles sont computationnellement moins coûteuses et sont même données pour rien dans certains cas. C’est le cas de <em>Merge</em>. <em>Move</em> au contraire est une opération complexe, donc coûteuse, qui n’intervient que quand elle est imposée par des considérations de dernier recours. Si des considérations d’économie imposent de sélectionner à chaque étape d’une dérivation l’option la moins coûteuse, on dérive la préférence énoncée en (10). Chomsky développe un argument supplémentaire qui pointe dans la même direction. Étant donné une numération N, <em>Merge</em> a la préférence à tous les points de la dérivation parce que, contrairement à <em>Move</em>, <em>Merge</em> contribue à vider la numération et que les numérations doivent être vides au moment où les dérivations atteignent leur terme.</p>
<p class="texte"><span class="paranumber">44</span>Mais cette préférence peut aussi s’appuyer sur des considérations empiriques. Les constructions en <em>there</em> fournissent les données requises. Il s’agit d’expliquer l’asymétrie entre les énoncés (a) et (b) en (11).</p>
<table class="example">
<tr>
<td>(11)</td>
<td>a. </td>
<td>*There is likely [a proof to be discovered].</td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>There is likely [<del>there</del> to be a proof discovered].</td>
</tr>
<tr>
<td> </td>
<td>c. </td>
<td>A proof is likely [<del>a proof</del> to be discovered].</td>
</tr>
<tr>
<td> </td>
<td>d. </td>
<td>[<sub>TP</sub> T<sub>non fini</sub> [be a proof discovered]]</td>
</tr>
</table>
<p class="texte"><span class="paranumber">45</span>Supposons que la dérivation ait atteint l’étape (11d) et que la catégorie Temps non fini soit dotée d’un trait [EPP]. Ce trait requiert que le spécifieur de la catégorie qui le porte soit projeté et occupé. Lorsqu’il est associé au Temps fini, ce trait code la propriété que tous les domaines propositionnels ont un sujet, exigence qui peut être satisfaite par l’insertion d’un explétif dans la position considérée (<em>Il semble que les étudiantes parlent le chinois couramment</em>) ou par le mouvement d’une expression nominale dans cette position (<em>Les étudiantes semblent parler le chinois couramment</em>). Si le Temps non fini porte aussi un trait [EPP], ce dernier peut a priori être satisfait soit par le déplacement de <em>a proof</em> dans son spécifieur, soit par l’insertion de l’explétif <em>there</em> (lorsque, bien sûr, il est présent dans la numération). La comparaison de (11a) et (11b) suffit à établir que, si <em>there</em> est présent dans la numération, c’est le <em>merger</em> de <em>there </em>qui doit intervenir ; <em>there</em> est d’abord inséré dans la position spécifieur du Temps subordonné et déplacé ensuite dans la position spécifieur du Temps matrice. (11c) indique qu’en l’absence de <em>there</em>, la question du choix ne se pose pas et que le mouvement de l’expression nominale est alors légitime.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">28</span> Collins (1997) a largement contribué à ce changement de perspective.</li>
</ul>
<p class="texte"><span class="paranumber">46</span>L’argument est ici que la dérivation sous-jacente à (11a) est moins économique que celle qui produit (11b), parce qu’elle choisit de recourir, dans l’enchâssée, à l’option la plus coûteuse, le mouvement, alors que le <em>merger</em> est disponible. Cette différence suffit à disqualifier la dérivation (11a), et ceci bien qu’un mouvement intervienne aussi <em>après</em> le <em>merger</em> de <em>there</em> dans la dérivation de (11b). Le principe explicatif est donc ici l’économie des dérivations. Le minimalisme, à ses débuts, a largement exploité cette notion d’économie, s’autorisant dans un premier temps à comparer des dérivations entières en termes de coût, pourvu qu’elles reposent sur la même numération, adoptant par la suite une conception strictement locale de l’économie, imposant qu’à chaque étape d’une dérivation, l’option la moins coûteuse soit sélectionnée.<a class="footnotecall" id="bodyftn28" href="#ftn28">28</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">29</span> (11a) est indépendamment exclu par des considérations casuelles. Dans sa position de surface, <em>a pro </em><a href="#ftn29">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">47</span>Castillo, Drury et Grohmann (1997, 2009) observent que la base empirique qui fournit à (10) sa motivation initiale est assez ténue, puisqu’elle se résume au contraste observé dans les constructions en <em>there </em>du type de (11). Avant de tirer des conclusions théoriques générales, il convient de s’assurer que l’analyse du contraste qui illustre la préférence de <em>Merge</em> sur <em>Move</em> est fondée. Or rien n’est moins sûr. L’analyse développée par Chomsky suppose en effet que le Temps non fini porte un trait [EPP], impliquant que la position sujet de la proposition non finie en (11) soit remplie à une étape de la dérivation et que, dans le cas des constructions à montée, elle définisse un passage obligé pour les termes déplacés dans la position sujet de la proposition matrice. Les auteurs notent que la présence de ce trait n’est nullement assurée et que d’autres analyses des structures infinitives sont possibles.<a class="footnotecall" id="bodyftn29" href="#ftn29">29</a></p>
</div>
<p class="texte"><span class="paranumber">48</span>Si, d’autre part, on considère d’autres constructions explétives, celles qui contiennent <em>it</em> ou <em>il</em> par exemple, on découvre que (10) fait une prédiction incorrecte. Soit les exemples (12a) et (13a). Supposons que la dérivation ait produit la structure (12b)/(13b), dans laquelle l’explétif, présent dans la numération, a été introduit dans la position sujet de la proposition subordonnée. Si l’on fait ce choix, la dérivation échoue, comme le montre l’agrammaticalité de (14a) et (14b).</p>
<table class="example">
<tr>
<td>(12)</td>
<td>a. </td>
<td>It seems that Mary was in the room.</td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>[<sub>TP</sub> it [<sub>T</sub> T-was [Mary [in the room]]]]</td>
</tr>
</table>
<table class="example">
<tr>
<td>(13)</td>
<td>a. </td>
<td>Il semble que Marie était dans la pièce. </td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>[<sub>TP</sub> il [<sub>T</sub> T-était [Marie [dans la pièce]]]]</td>
</tr>
</table>
<table class="example">
<tr>
<td>(14)</td>
<td>a. </td>
<td>*Mary seems that it was in the room.</td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>*Marie semble qu’il était dans la pièce. </td>
</tr>
<tr>
<td> </td>
<td> </td>
<td>(où <em>il</em> est le pronom explétif)</td>
</tr>
</table>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">30</span> Sur le phénomène de super-montée et la Condition de minimalité, voir chapitres VII et IX.</li>
</ul>
<p class="texte"><span class="paranumber">49</span>Si la dérivation a produit la structure (13b), <em>Marie</em> doit se déplacer par-dessus l’explétif pour atteindre la position sujet de la proposition matrice. Une situation de type super-montée est produite, dans laquelle la Condition de minimalité est violée.<a class="footnotecall" id="bodyftn30" href="#ftn30">30</a></p>
</div>
<p class="texte"><span class="paranumber">50</span>La situation se complique encore davantage quand on prend en considération les exemples (15), généralement attribués à Marantz, et leurs contreparties françaises (16) :</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">31</span> Le symbole t<sub>i</sub> (pour « trace de i ») marque la position originelle de l’expression nominale antéposé <a href="#ftn31">(...)</a></li>
</ul>
<table class="example">
<tr>
<td>(15)</td>
<td> a. </td>
<td>There was [a rumor [that a man<sub>i</sub> was t<sub>i</sub> in the room]] in the air.</td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>[A rumor [that there was a man in the room]]<sub>i</sub> was t<sub>i </sub>in the air.<a class="footnotecall" id="bodyftn31" href="#ftn31">31</a></td>
</tr>
</table>
</div>
<table class="example">
<tr>
<td>(16)</td>
<td>a. </td>
<td>Il y avait dans l’air [une rumeur [qu’un homme<sub>i</sub> était t<sub>i</sub> dans la pièce]]. </td>
</tr>
<tr>
<td> </td>
<td>b. </td>
<td>[Une rumeur [qu’il y avait un homme dans la pièce]]<sub>i</sub> était t<sub>i</sub> dans l’air.</td>
</tr>
</table>
<p class="texte"><span class="paranumber">51</span>Cette paire d’exemples semble indiquer qu’il existe des cas où le choix est ouvert, ce qui est inattendu si la préférence (10) opère de façon strictement locale. Or (15a) et (15b), (16a) et (16b) sont acceptables l’un et l’autre et dérivés de la même numération. L’existence de (15b) devrait bloquer (15a) et le mouvement de <em>a man</em> dans la complétive dépendante de <em>rumor</em>, parce que l’insertion de <em>there</em> dans cette proposition devrait être imposée par (10). Pour accommoder cette situation, Castillo, Drury et Grohmann proposent que la convergence des domaines TP concernés soit évaluée dérivationnellement, de façon cyclique. Dans cette hypothèse, les dérivations de (15) et de (16) sont fractionnées en deux sous-dérivations – celle de la complétive et celle de la principale – qui doivent converger indépendamment l’une de l’autre. Le choix du matériel occupant la position sujet de la complétive n’a aucune incidence sur la convergence de la proposition principale. Si <em>there</em> (ou <em>il</em>) fait partie de la numération associée à la complétive, l’output de la dérivation est (15b) ou (16b) ; s’il fait partie de la numération associée à la principale, l’output est (15a) ou (16a). La bonne formation de (12a) et de (13a) peut être expliquée dans les mêmes termes, tout comme l’agrammaticalité de (14a) et de (14b). (14b) correspond à la situation dans laquelle l’explétif <em>il</em> fait partie de la numération associée à la subordonnée. Or, à ce point de la dérivation, <em>Marie</em>, qui en fait également partie, ne peut vérifier son trait de Cas. C’est l’explétif qui entre en relation avec le trait nominatif sur le Temps fini enchâssé. La dérivation, qui ne converge pas au niveau du TP enchâssé, échoue. Chomsky reprend le problème dans <em>MI</em> et montre que l’hypothèse des phases et du <em>Spell-Out </em>cyclique permet de résoudre le problème posé par les exemples (12)-(16). La solution qu’il propose ne pourra être présentée en détail qu’une fois précisée la nature de <em>Spell-Out</em> et introduite la notion de phase (voir 6.1 et VIII).</p>
<p class="texte"><span class="paranumber">52</span>La discussion des exemples (12)-(16) repose sur l’idée que les opérations <em>Merge</em> et <em>Move</em> ne sont pas ordonnées l’une par rapport à l’autre : les séquences <em>Merge</em> + <em>Move</em> + <em>Merge </em>sont légitimes. Elle indique également qu’une notion de cyclicité reste nécessaire dans un système qui fait l’économie du niveau de représentation D, comme l’observent Hornstein, Nunes et Grohmann (2005).</p>
<h1 class="texte"><a href="#tocfrom1n5" id="tocto1n5">5. <em>Spell-Out</em></a></h1>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">32</span> Sur cette asymétrie, voir la section 1 de ce chapitre, ainsi que la section 6 du chapitre I.</li>
</ul>
<p class="texte"><span class="paranumber">53</span>Aucun niveau d’interface, PF pas plus que LF, ne peut contenir de trait ininterprétable à ce niveau. Or rappelons qu’une conséquence de l’architecture en Y est qu’il n’y a pas, touchant la convergence, d’interaction possible entre PF et LF. Un trait lisible à une interface ne l’est habituellement pas à l’autre. La matrice de traits phonologiques correspondant aux obstruantes continues, [+ consonantique, – sonante, + continue], n’est pas lisible à l’interface LF. Aucun des traits syntaxiques ou sémantiques de la matrice correspondant au nom <em>garçon</em>, [+ N, + dénombrable, + commun, + animé, + humain], n’est lisible à l’interface PF. Pour que la dérivation converge, il est absolument nécessaire que les traits lisibles à une interface ne soient pas présentés à l’autre. C’est précisément la fonction de <em>Spell-Out</em> (« épellation ») que de partitionner l’ensemble des traits associés à une structure Σ. À un point de la computation faisant correspondre à une numération N une représentation de LF λ, intervient une opération, <em>Spell-Out</em>, qui s’applique à la structure Σ déjà formée et dépouille Σ et les items lexicaux qu’elle contient de leurs propriétés phonologiques, c’est-à-dire des éléments qui ne sont pertinents que pour la dérivation de la représentation π. Cette opération laisse un résidu Σ<sub>L</sub>, auquel des règles analogues à celles qui ont formé Σ font correspondre la représentation λ. Le sous-système qui dérive Σ à partir de N est la « syntaxe explicite » (<em>overt syntax</em>) ; celui qui poursuit la computation vers LF et applique Σ<sub>L </sub>sur λ est la « syntaxe silencieuse » (<em>covert syntax</em>) ; celui qui applique Σ sur π est le composant phonologique<em>.</em><em>Spell-Out</em> est donc une opération, non un niveau, et cette opération peut en droit intervenir à n’importe quel point de la dérivation, parce qu’elle n’est pas liée à la satisfaction d’une condition ou d’un principe particulier. Le terme choisi par Chomsky, que l’on peut traduire par « épellation », traduit à nouveau une conception asymétrique des interfaces PF et LF. Il marque que cette opération est un transfert vers PF, qui se greffe sur la « computation uniforme » qui à une numération N fait correspondre une représentation de LF λ, désignée sous l’étiquette de « syntaxe étroite ».<a class="footnotecall" id="bodyftn32" href="#ftn32">32</a> En même temps, cette opération, qui interdit aux traits phonologiques tout accès à la computation syntaxique ultérieure dérivant λ, marque la frontière entre la syntaxe explicite et la syntaxe silencieuse.</p>
</div>
<p class="texte"><span class="paranumber">54</span>L’architecture grammaticale qui résulte de ces hypothèses n’est pas fondamentalement différente du schéma en Y du modèle des Principes et Paramètres. Ce dernier est représenté en (17).</p>
<table class="example">
<tr>
<td>(17)</td>
<td>Architecture de la grammaire dans le modèle des Principes et Paramètres</td>
</tr>
</table>
<div class="textIcon"><a href="docannexe/image/5607/img-1-small700.jpg" rel="iconSet"><img src="docannexe/image/5607/img-1-small517.jpg" alt="" /></a><div class="textIconAccess"><a rel="nofollow" class="iconZoom" href="docannexe/image/5607/img-1-small700.jpg">Vergrößern</a> <a rel="nofollow" class="iconOrig" href="docannexe/image/5607/img-1.jpg">Originaldatei (jpeg, 34k)</a></div>
</div>
<p class="texte"><span class="paranumber">55</span>Un dispositif grammatical faisant l’économie des niveaux internes, la structure D et la structure S, peut être schématisé comme suit :</p>
<table class="example">
<tr>
<td>(18)</td>
<td> Architecture du dispositif minimaliste dans <em>C&amp;T</em></td>
</tr>
</table>
<div class="textIcon"><a href="docannexe/image/5607/img-2-small700.jpg" rel="iconSet"><img src="docannexe/image/5607/img-2-small517.jpg" alt="" /></a><div class="textIconAccess"><a rel="nofollow" class="iconZoom" href="docannexe/image/5607/img-2-small700.jpg">Vergrößern</a> <a rel="nofollow" class="iconOrig" href="docannexe/image/5607/img-2.jpg">Originaldatei (jpeg, 29k)</a></div>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">33</span> Bošković (1998) observe que cet argument n’exclut pas totalement l’insertion lexicale tardive. Il a <a href="#ftn33">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">56</span>On a à nouveau affaire à une architecture en Y. La différence essentielle entre (17) et (18) est qu’en (18), la structure syntagmatique est construite pas à pas, de bas en haut, par des opérations, <em>Merge</em> et <em>Move</em>, qui manipulent les items lexicaux eux-mêmes et s’appliquent récursivement, sans recourir à une structure préconstruite. Une deuxième différence réside dans l’absence de structure S. C’est l’opération <em>Spell-Out</em> qui assure la démarcation entre la syntaxe explicite et la syntaxe silencieuse et qui marque le point où les traits phonologiques cessent d’être accessibles à la computation syntaxique. Il faut se souvenir que <em>Spell-Out</em> n’est pas un niveau de représentation, auquel s’appliqueraient certains principes spécifiques, mais une simple opération. Cela ne signifie pas nécessairement que les opérations syntaxiques postérieures à <em>Spell-Out</em> sont identiques à celles qui précèdent. Il existe plusieurs conceptions du mouvement silencieux, qui seront examinées en X. Il est possible qu’après <em>Spell-Out</em>, le mouvement se réduise à un mouvement de traits ou au contraire implique des objets syntaxiques structurés. Il paraît exclu, d’autre part, d’appliquer <em>Merge</em> après <em>Spell-Out</em> et de faire une insertion lexicale tardive dans le trajet vers LF ou dans le trajet vers PF. Comme l’observe Chomsky dans <em>C&amp;T</em>, cette impossibilité suit du Principe de l’interprétation intégrale FI. Si un élément comme <em>table</em> est inséré en PF, le composant PF ne pourra interpréter ses traits sémantiques. Inversement, si un élément est inséré en LF, le système LF ne pourra interpréter ses traits phonologiques. La seule option légitime consiste à insérer <em>table</em> avant <em>Spell-Out</em>, dans la syntaxe explicite.<a class="footnotecall" id="bodyftn33" href="#ftn33">33</a></p>
</div>
<h1 class="texte"><a href="#tocfrom1n6" id="tocto1n6">6. Un nouveau dispositif</a></h1>
<p class="texte"><span class="paranumber">57</span>C’est un dispositif différent qui est mis en place dans <em>MI</em> et <em>DbP</em>, reconduit et affiné dans les articles suivants, <em>BEA</em>, <em>TF</em> et <em>OPh</em>. Si l’on prend comme référence les propositions avancées dans <em>BEA</em>, on peut le représenter comme suit :</p>
<table class="example">
<tr>
<td>(19)</td>
<td> Architecture du dispositif minimaliste (dans <em>BEA</em>)</td>
</tr>
</table>
<div class="textIcon"><a href="docannexe/image/5607/img-3-small700.jpg" rel="iconSet"><img src="docannexe/image/5607/img-3-small517.jpg" alt="" /></a><div class="textIconAccess"><a rel="nofollow" class="iconZoom" href="docannexe/image/5607/img-3-small700.jpg">Vergrößern</a> <a rel="nofollow" class="iconOrig" href="docannexe/image/5607/img-3.jpg">Originaldatei (jpeg, 48k)</a></div>
</div>
<p class="texte"><span class="paranumber">58</span>Ce schéma architectural s’écarte de façon significative du modèle représenté en (18). La terminologie est différente. Dans <em>BEA</em>, Chomsky ne parle plus de <em>Spell-Out</em>, mais de <em>Transfer</em> (transfert). Il n’est plus question des composants LF ou PF, ni des niveaux de représentation de même étiquette, mais des composants Σ et Φ. Ces composants ne débouchent pas sur des <em>niveaux</em> de représentation, mais produisent des <em>fragments</em> de représentation SEM et PHON, en relation d’interface avec C-I et SM, comme l’indiquent les définitions et caractérisations suivantes (<em>BEA</em>, p. 107).</p>
<table class="example">
<tr>
<td>(20)</td>
<td>L a trois composants : </td>
</tr>
<tr>
<td> </td>
<td>la syntaxe étroite (<em>narrow syntax</em>, NS) applique LA sur une dérivation D<sub>NS</sub> ;</td>
</tr>
<tr>
<td> </td>
<td>le composant phonologique Φ applique D<sub>NS</sub> sur PHON ;</td>
</tr>
<tr>
<td> </td>
<td>le composant sémantique Σ applique D<sub>NS</sub> sur SEM.</td>
</tr>
</table>
<table class="example">
<tr>
<td>(21)</td>
<td><em>Transfer</em> transmet D<sub>NS</sub> à Φ et à Σ.</td>
</tr>
</table>
<p class="texte"><span class="paranumber">59</span>Les différences portent sur deux points : la cyclicité de <em>Spell-Out/Transfer</em>, la caractérisation des interfaces et la nature des objets qui leur sont transmis.</p>
<h2 class="texte"><a href="#tocfrom2n4" id="tocto2n4">6.1. <em>Spell-Out /</em><em>Transfer</em> cyclique</a></h2>
<p class="texte"><span class="paranumber">60</span>Le premier changement, amorcé dès <em>MI</em>, concerne la cyclicité des dérivations. La nécessité conceptuelle n’impose nullement la présence de quelque niveau de représentation que ce soit, c’est-à-dire de structures pleinement développées proposant des représentations intégrées du son et de la signification d’un énoncé. Elle requiert par contre que soient disponibles des fragments de représentation sur lesquels les mécanismes interprétatifs puissent opérer. Si ce choix théorique a la préférence, on n’aura plus de niveaux d’interface LF et PF – donc, plus de niveaux de représentation du tout, puisque les niveaux internes, D et S, ont été éliminés –, mais on devra bien sûr conserver un composant sémantique – Σ en (19) – et un composant phonologique – Φ en (19). Plusieurs modèles de ce type ont été proposés, le modèle strictement dérivationnel d’Epstein, Groat, Kawashima et Kitahara (1998), le modèle du <em>Spell-Out</em> multiple d’Uriagareka (1999b) et la théorie des phases de Chomsky (<em>MI</em>, <em>DbP</em>, <em>BEA</em>, <em>TF</em>, <em>OPh</em>), directement inspirée par la proposition d’Uriagereka. Chomsky fait l’hypothèse que l’interprétation sémantique et l’interprétation phonologique ne sont pas construites à un niveau de représentation spécifique produit par la dérivation syntaxique, mais interviennent à plusieurs étapes de la dérivation, à mesure que la construction de la structure progresse. Il n’y a pas un <em>Spell-Out</em> unique, mais un <em>Spell-Out</em> cyclique. Chomsky désigne les étapes correspondantes sous l’étiquette de « phases » et pose que les domaines CP et vP définissent des phases (voir VII et VIII).</p>
<p class="texte"><span class="paranumber">61</span>Le schéma (19) intègre l’idée du cycle unique déjà évoqué dans la section 1. L’accès de C<sub>HL </sub>aux interfaces est désormais cyclique. Les trois cycles indépendants des modèles précédents – syntaxe explicite, syntaxe silencieuse, interprétation phonologique, voir (18) – se réduisent à un cycle unique qui, à chaque phase, applique une collection structurée d’items lexicaux sur l’interface sémantique et sur l’interface phonologique, cette dernière application étant conçue comme un processus secondaire. Le schéma en Y ne vaut plus globalement pour la phrase tout entière, mais pour chaque cycle dérivationnel. L’hypothèse est désormais que l’insertion d’un v ou d’un C à un point de la dérivation crée un sous-domaine pour la computation et qu’une fois effectuées toutes les opérations pouvant intervenir au niveau vP ou CP, l’objet syntaxique résultant est « transféré » et peut être oublié par les computations ultérieures. La sélection lexicale, l’accord, le mouvement, le transfert donnant accès aux interfaces et donc l’épellation elle-même opèrent chacun au niveau phasal. <em>Spell-Out</em>, qui opère en droit à n’importe quel point de la dérivation, intervient en fait désormais à des points déterminés : à la complétion des phases vP et CP.</p>
<p class="texte"><span class="paranumber">62</span>Les raisons qui appuient cette innovation théorique seront examinées en détail dans le chapitre VIII. Observons pour l’instant qu’elle fournit une solution simple à la difficulté soulevée par les exemples (15) et (16) à l’encontre d’un modèle du type de (18). Le problème est très général et peut être formulé comme suit : dans l’hypothèse où l’application des opérations simples bloque celle des opérations complexes, pourquoi la montée d’une expression nominale est-elle malgré tout possible quand un explétif est disponible dans la numération pour satisfaire le trait [EPP] de T ? La réponse de Chomsky reprend la conclusion de Castillo, Drury et Grohmann (1999) : l’explétif peut ne pas être accessible à l’étape pertinente. Seule une sous-partie de la numération, une sous-sélection lexicale (<em>lexical subarray</em>), est accessible à un point donné de la dérivation et l’explétif peut ne pas être inclus dans cette sous-sélection. Dans ce cas, seul le déplacement d’une expression nominale peut vérifier [EPP]. Chomsky propose que l’accès de C<sub>HL </sub>à la numération soit lui-même cyclique et opère par phases. C’est même le phénomène illustré en (15) et (16) qui fournit la motivation initiale justifiant l’intégration des phases au dispositif grammatical. Cette proposition produit bien le résultat cherché : l’explétif <em>there/il</em> peut faire ou ne pas faire partie de la sous-sélection associée à la complétive. Dans le premier cas, l’insertion de l’explétif par <em>Merge</em> est l’option préférée, du fait de (10) ; (15b)/(16b) sont produits. Dans le second cas, l’insertion de l’explétif dans la complétive n’est tout simplement pas une option, puisqu’il ne fait pas partie de la sous-numération pertinente. Seul le mouvement de <em>a man / un homme</em> est possible, donnant (15a)/(16a). Le contraste entre (11a) et (11b) peut toujours être invoqué comme un argument empirique appuyant la préférence de <em>Merge </em>sur <em>Move</em>. On a affaire à une construction à montée dans laquelle le verbe matrice et la proposition enchâssée appartiennent à la même phase ; (10) est donc opératoire dans les limites d’une phase. En conclusion, le phénomène qui posait problème dans une conception non phasale de la numération se trouve résolu si on intègre les phases à la théorie.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">34</span> Enfin, l’incertitude n’a pas été pleinement dissipée touchant la présence d’un trait [EPP] sur la c <a href="#ftn34">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">63</span>Observons pour conclure que la préférence supposée de <em>Merge</em> sur <em>Move</em>, qui sert à motiver un trait important de la théorie des phases, a été peu à peu remise en question. La base empirique du théorème (10) s’est révélée fragile. De plus, les articles du milieu des années deux mille cessent de postuler une différence entre <em>Merge</em> et <em>Move </em>en termes de coût computationnel. <em>Move </em>est désormais construit comme une instance particulière de <em>Merge</em>, comme un <em>Merge</em> interne (<em>internal Merge</em>, IM) qui s’oppose au <em>Merge</em> externe (<em>external Merge</em>, EM), correspondant au <em>Merge</em> classique (voir note 27). Les deux opérations sont donc désormais également accessibles au cours de la dérivation. Si la préférence de <em>Merge</em> sur <em>Move </em>est avérée, elle doit être dérivée autrement, sans référence au coût computationnel des opérations.<a class="footnotecall" id="bodyftn34" href="#ftn34">34</a></p>
</div>
<p class="texte"><span class="paranumber">64</span>Il est d’autant plus troublant de constater que, bien que la caractérisation de <em>Move</em> comme une opération complexe, coûteuse et non imposée par la nécessité conceptuelle, ait été peu à peu abandonnée, la théorie des phases qui procède en partie de cette caractérisation n’a pas été remise en question. Au contraire, son rôle dans le dispositif s’est accru. L’innovation théorique a été maintenue, bien que le problème qu’elle était supposée résoudre se pose désormais en termes différents.</p>
<h2 class="texte"><a href="#tocfrom2n5" id="tocto2n5">6.2. LF/SEM</a></h2>
<p class="texte"><span class="paranumber">65</span>Le second changement architectural, intervenu dans <em>BEA</em>, engage la notion d’interface elle-même et la caractérisation du type d’objet que les opérations sémantiques et phonologiques transmettent aux systèmes d’interface C-I et SM.</p>
<p class="texte"><span class="paranumber">66</span>On n’a plus, comme dans les versions antérieures du modèle, des <em>représentations</em> intégrées, complètes, de la signification (LF) ou du son (PF), objets cohérents présentés à un point d’interface aux systèmes externes avec lesquels la Faculté de Langage est en relation. On a par contre des <em>fragments de représentation</em>, produits par la dérivation par phase et par les composants externes d’interprétation et de réalisation Σ et Φ, transmis aux systèmes d’interface C-I et SM. Dans le schéma (19), SEM est l’objet interprété, présenté au système C-I et résultant des opérations sémantiques dans le composant Σ. Chomsky commente :</p>
<blockquote>
<p class="citation">Dans cette conception, il n’y a pas de LF. La computation applique LA [l’échantillon lexical] sur la paire &lt;PHON, SEM&gt;, fragment par fragment, cycliquement. Il n’y a donc pas de propriétés de LF, ni d’interprétation à LF, à proprement parler, bien que Σ et Φ interprètent des unités qui font partie de quelque chose comme LF dans une conception non cyclique. (<em>BEA</em>, p. 107)</p>
</blockquote>
<p class="texte"><span class="paranumber">67</span>Cette observation est réitérée dans <em>OPh</em> (voir aussi <em>AUGB</em>, note 23) :</p>
<blockquote>
<p class="citation">Une confusion a été créée par l’emploi récent du terme LF pour référer à l’interface C-I elle-même, ce qui s’écarte de la définition de la Théorie Standard Étendue, qui la caractérise comme l’output des opérations syntaxiques (explicites ou implicites) et l’input des règles d’interprétation sémantique qui appliquent LF sur C-I. (<em>OPh</em>, note 11)</p>
</blockquote>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">35</span> Hinzen (2006) cite l’exemple suivant fourni par Martin et Uriagereka (2000) qui admet une seule rep <a href="#ftn35">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">68</span>La notion de syntaxe étroite, utilisée en (20) et (21), désigne, quant à elle, le parcours computationnel qui va de la numération jusqu’au point où <em>Transfer </em>opère, transmettant l’output de la dérivation D<sub>NS</sub> aux composants Φ et Σ. Mais ce parcours inclut aussi les opérations de la syntaxe silencieuse qui, dans les dispositifs précédents, intervenaient dans la dérivation de ce qui était appelé LF. Selon qu’elle intervient avant ou après <em>Transfer</em>, une opération de déplacement sera explicite ou silencieuse. La position de Chomsky dans <em>BEA</em> est qu’effectivement, certains processus de mouvement prennent place après <em>Transfer</em> (voir X.1). Syntaxe explicite et syntaxe silencieuse partagent la propriété de recourir à l’opération <em>Move</em> et de définir l’espace dérivationnel dans lequel les traits ininterprétables sont valués par <em>Agree</em>. La raison pour laquelle LF ne se confond pas avec l’interface C-I est que d’autres opérations peuvent intervenir après la syntaxe silencieuse qui, elles, impliquent un calcul sémantique, ne prenant pas nécessairement appui sur la syntaxe.<a class="footnotecall" id="bodyftn35" href="#ftn35">35</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">36</span> Dans les chapitres qui suivent, je continuerai à désigner LF comme un niveau d’interface – ce qu’el <a href="#ftn36">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">69</span>Il est donc nécessaire d’établir une distinction nette entre NS et Σ. Σ n’est pas une étape supplémentaire de la syntaxe étroite, mais utilise des ressources différentes de celles qui sont disponibles dans la syntaxe étroite, où la Condition d’inclusion est rigoureusement observée. <em>Transfer</em> intervient donc à un point de la dérivation de la syntaxe étroite, traçant une démarcation entre syntaxe explicite et syntaxe silencieuse. Les opérations postérieures à la syntaxe étroite sont elles-mêmes suivies par des processus sémantiques de nature différente. La séquence dérivationnelle supposée par Chomsky devrait en réalité être représentée comme suit :<a class="footnotecall" id="bodyftn36" href="#ftn36">36</a></p>
</div>
<table class="example">
<tr>
<td>(22)</td>
<td>C<sub>HL</sub> (syntaxe explicite) ➔ <em>Transfer</em> ➔ C<sub>HL</sub> (syntaxe silencieuse) ➔ LF ➔ opérations sémantiques ➔ SEM // C-I</td>
</tr>
</table>
<p class="texte"><span class="paranumber">70</span>Le transfert est cyclique, les opérations de la syntaxe étroite postérieures au transfert le sont aussi, tout comme les opérations de la syntaxe explicite. Mais il existe des opérations sémantiques post-LF qui échappent à cette condition. Cette hypothèse est en fait inévitable si l’on admet que l’interprétation sémantique est construite à partir des fragments de LF produits cycliquement dans l’hypothèse du <em>Spell-Out</em> phasal. Ces fragments doivent être réassemblés pour que l’interprétation sémantique soit possible. Le phénomène de l’anaphore à distance peut servir à illustrer ce point, tout comme le liage des variables à distance.</p>
<table class="example">
<tr>
<td>(23)</td>
<td> On ne souhaite pas que personne dise du mal de soi.</td>
</tr>
</table>
<table class="example">
<tr>
<td>(24)</td>
<td> Chaque enfant est bouleversé par la rumeur que son père est infidèle.</td>
</tr>
</table>
<p class="texte"><span class="paranumber">71</span>Dans l’une des interprétations de (23), <em>soi</em> doit entrer en relation avec le pronom indéfini <em>on</em>, qui n’est pas inclus dans la phase contenant <em>soi</em>. En (24), le liage de la variable pronominale implique aussi une unité plus étendue que la phase qui la contient. La caractérisation strictement phasale de la syntaxe étroite rejette donc hors de celle-ci certaines propriétés sémantiques et phonologiques globales des expressions et des énoncés.</p>
<p class="texte"><span class="paranumber">72</span>Trois points doivent être soulignés en guise de conclusion.</p>
<p class="texte"><span class="paranumber">73</span>Les architectures minimalistes (19) et (19) considérées dans ce chapitre, par-delà leurs différences, partagent une caractéristique essentielle : la syntaxe et la sémantique constituent un composant unique, dont se trouve exclue la phonologie, qui correspond à un composant autonome. Sous-jacente à cette organisation, il y a l’idée que le langage a, de façon nécessaire, partie liée avec la signification et que le fait qu’il emprunte le canal des sons (ou un autre canal) est en partie accidentel. C’est, avec l’hypothèse du cycle unique, l’innovation principale du minimalisme touchant l’architecture de la Faculté de Langage.</p>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">37</span> En termes différents, on peut dire qu’il est nécessaire de distinguer entre la modularité <em>interne</em>, <a href="#ftn37">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">74</span>Mais la référence à Σ et à Φ dans le schéma (19) montre que le minimalisme maintient l’idée, héritée des modèles antérieurs, que la Faculté de Langage est organisée en modules, qui produisent des objets, spécifient leurs conditions de bonne formation et établissent des relations de <em>mapping</em> entre eux. Au sein de la Faculté de Langage, on doit donc soigneusement distinguer entre la syntaxe proprement dite et les composants externes Φ et Σ. On doit aussi distinguer entre les composants externes et les systèmes d’interface. C’est ainsi qu’il faut interpréter la note 11 de <em>OPh</em>, mentionnée plus haut, dans laquelle Chomsky met en garde contre la confusion possible entre ce qui était désigné précédemment sous l’étiquette LF, output des opérations syntaxiques (explicites ou silencieuses) et input des règles d’interprétation sémantique menant à la dérivation de SEM, et l’interface C-I elle-même. Cette confusion correspond à une absence de distinction entre composants externes et systèmes d’interface.<a class="footnotecall" id="bodyftn37" href="#ftn37">37</a></p>
</div>
<div class="textandnotes">
<ul class="sidenotes">
<li><span class="num">38</span> La seule interface qui pourrait être considérée est celle qui associe le Lexique et la Syntaxe. Pou <a href="#ftn38">(...)</a></li>
</ul>
<p class="texte"><span class="paranumber">75</span>Il est clair que la notion d’interface ne peut être définie de façon interne à la Faculté de Langage. Dans le modèle des Principes et Paramètres, la structure S ne se trouvait en relation d’interface avec rien, c’est-à-dire avec aucun système externe à la Faculté de Langage. Dans le Programme Minimaliste, <em>Spell-Out</em> ne correspond pas à un niveau de représentation autonome, n’étant qu’une opération dans le trajet allant de la numération vers NS.<a class="footnotecall" id="bodyftn38" href="#ftn38">38</a> Bref, la SMT ne vaut que pour les interfaces de la Faculté de Langage avec les systèmes C-I et SM – en fait, elle ne vaut que pour l’interface C-I, voir (6). Elle ne dit rien sur la relation entre la syntaxe (entendue au sens étroit) et les composants interprétatifs. On pourrait imaginer que la forme et le contenu du composant syntaxique soient en partie déterminés par la relation qu’il entretient avec les composants externes Φ et Σ. Si ce point de vue était adopté, on serait fondé à dire que le minimalisme explore à la fois la nature et les propriétés de la Faculté de Langage à la lumière des systèmes avec lesquels elle est en relation d’interface et la nature et les propriétés du système computationnel à la lumière des composants de réalisation et d’interprétation. Bien que cette question ne soit pas abordée dans les discussions minimalistes, il est clair que cette conception n’est pas celle de Chomsky. La SMT ne peut concerner que la relation entre la Faculté de Langage et ses interfaces, imposant une condition de lisibilité aux fragments de représentation qu’elle leur transmet. Il n’existe par définition aucun niveau d’interface <em>interne</em> à la Faculté de Langage.</p>
</div> </div> </div>
<div id="notes">
<h2 class="section">Anmerkungen</h2>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn1" id="ftn1">1</a> Le composant syntaxique coïncide avec la jambe du Y, les composants interprétatifs correspondent à chacune des deux branches.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn2" id="ftn2">2</a> On doit distinguer entre le I-langage, abordé comme un objet de la nature, et la représentation qui en est proposée, sous la forme d’un Lexique et d’un mécanisme computationnel. Dans le chapitre I, j’ai traduit <em>I-language</em> par « I-langage ». Dans la mesure où le système ainsi désigné se développe chez l’individu à partir d’un état initial vers un état stable et est une propriété de l’esprit/cerveau, « I-langue » pourrait aussi être une traduction appropriée. Je laisse la question ouverte.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn3" id="ftn3">3</a> On dit de LF et de PF que ce sont des niveaux d’interface parce que c’est par leur intermédiaire que le système que constitue la Faculté de Langage entre en relation avec d’autres aspects de la réalité mentale et physique.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn4" id="ftn4">4</a> Le mot trait en (2) a le sens très général de « propriété spécifique associée à un objet », et non l’acception technique particulière qu’il a, par exemple, dans l’expression « trait phonologique ». </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn5" id="ftn5">5</a> Je reprends l’usage introduit par Lisa Selkirk, consistant à noter les barres au moyen d’apostrophes.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn6" id="ftn6">6</a> La Théorie Standard Étendue intégrait un autre principe que l’on peut, comme (2), interpréter comme une contrainte de préservation ou de conservation, la Condition de récupérabilité qui, dans sa formulation initiale, concernait exclusivement les effacements et posait que tout matériel effacé doit être récupérable à partir de l’environnement local. Cette condition n’est pas reprise dans le minimalisme. On peut observer que la Condition de non-altération, formulée en (38), chapitre IV, dont on peut supposer qu’elle n’est opérante que dans la syntaxe étroite, implique que les effacements intervenant dans la dérivation des constructions élidées, qui modifient des objets syntaxiques déjà construits, interviennent sur la branche PF de la grammaire.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn7" id="ftn7">7</a> Le trait de Cas structural sur les noms appartient à cette classe. La fonction du Cas est purement syntaxique, puisqu’elle se limite à régler la distribution des noms et des pronoms dans les structures. Voir chapitre III.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn8" id="ftn8">8</a> Lasnik et Uriagereka (2005, p. 8) observent que les étiquettes <em>Deep structure </em>et <em>Surface structure</em> ont été source de malentendu, dès leur première utilisation : « Il n’y avait rien de profond dans la <em>Deep structure</em> et rien de superficiel dans la <em>Surface structure</em>. » C’est très probablement la raison pour laquelle Chomsky dans <em>LGB</em> leur substitue celles de <em>D-structure</em> et de <em>S-structure</em>.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn9" id="ftn9">9</a> Si la conclusion concernant la structure S paraît légitime, le sort réservé à la structure D paraît discutable. Comme l’observe Uriagereka dans son commentaire à <em>MI</em>, on pourrait caractériser cette dernière comme entretenant une relation d’interface avec le Lexique, dont, rappelons-le, le système computationnel est strictement disjoint. La SMT, d’autre part, n’impose pas de limite sur le nombre de niveaux. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn10" id="ftn10">10</a> Notons que le Principe de l’interprétation intégrale, principe de bonne formation sur les représentations introduit en 1986 dans <em>KoL</em>, assignait déjà un statut particulier aux niveaux PF et LF, qui « constituent l’interface de la Faculté de Langage avec d’autres systèmes cognitifs », avec le résultat que « les conditions de légitimation à PF et LF sont en un sens externes » (<em>KoL</em>, p. 100).</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn11" id="ftn11">11</a> Dans les constructions passives et dans les constructions à montée, l’expression nominale se déplace d’une position non casuellement marquée vers une position où elle peut recevoir un Cas. Une expression nominale réalisée dans la position occupée par la trace en (i) et (ii) ne satisfait pas le Filtre sur le Cas. Ce dernier intervient donc nécessairement après les déplacements.</p>
<table class="example">
<tr>
<td></td>
<td>(i)</td>
<td>Le problème<sub>i</sub> a été résolu t<sub>i</sub></td>
</tr>
<tr>
<td> </td>
<td>(ii)</td>
<td>Jean<sub>i</sub> semble [t<sub>i</sub> avoir résolu le problème]</td>
</tr>
</table>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn12" id="ftn12">12</a> Sur la reconstruction, voir en particulier Fox (1999, 2000) et X.3.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn13" id="ftn13">13</a> Ce qui revient à dire que ce sont les têtes de chaîne qui sont prononcées. Cette hypothèse est sans aucun doute la plus simple imaginable, mais elle doit être aménagée pour tenir compte des situations dans lesquelles un mouvement syntagmatique silencieux est impliqué (voir la discussion en X.1) et celles dans lesquelles plusieurs positions dans une chaîne sont prononcées (ce pourrait être l’analyse correcte des constructions à copie du verbe en chinois, si l’on peut montrer que les deux occurrences verbales appartiennent bien à la même chaîne).</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn14" id="ftn14">14</a> Voir aussi sur ce point le chapitre II de Hornstein, Nunes et Grohmann (2005). </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn15" id="ftn15">15</a> La notion de chaîne est discutée en VII.4.4.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn16" id="ftn16">16</a> La condition excluant que les deux arguments d’un verbe transitif, l’argument externe et l’argument direct, conservent l’un et l’autre leur position originelle interne au vP pourrait appartenir à cette classe. Voir V.1.2, pour une discussion des exemples pertinents. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn17" id="ftn17">17</a> On peut imaginer la situation suivante : une information est disponible à un point de la dérivation, elle est exploitée par le système computationnel, mais elle est perdue et donc inexploitable aux étapes ultérieures ; pourtant ses effets se manifestent clairement dans l’output de la dérivation. Si de telles situations existent, elles appuient évidemment l’approche dérivationnelle, au détriment des approches monostratales. Un exemple de ce type est fourni par l’interaction entre la <em>Nuclear Stress Rule</em> et le mouvement <em>wh</em> en anglais, discutée par Bresnan (1971) : un élément interrogatif déplacé se comporte, du point de vue de l’accent, comme s’il occupait sa position originelle, ce qui suggère que certains processus phonologiques interviennent avant certaines opérations syntaxiques de mouvement. Une approche dérivationnelle peut capturer cette généralisation sans difficulté. Il n’en va pas de même pour une approche représentationnelle. Voir VIII.1 pour une discussion. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn18" id="ftn18">18</a> Le concept de numération, tel qu’il est introduit par Chomsky, rappelle celui de « multi-ensemble », utilisé par les informaticiens. Un multi-ensemble se distingue d’un ensemble classique par le fait que chaque élément peut apparaître un nombre quelconque de fois. Par exemple, un multi-ensemble qui contient deux fois l’élément a, trois fois l’élément b et une fois l’élément c peut être noté {a, a, a, b, b, c} ou bien {{a, 2}, {b, 3}, {c, 1}}, où le second élément de chaque paire indique le nombre d’occurrences. Je dois cette précision à Jakub Kallas.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn19" id="ftn19">19</a> Dans ce qui suit, j’utiliserai indifféremment les étiquettes « numération » et « échantillon lexical ».</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn20" id="ftn20">20</a> <em>Merge</em> est souvent traduit par « fusionner » en français. « Assembler » me paraît préférable. « Combiner » est aussi une possibilité. Je maintiendrai ici l’original anglais. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn21" id="ftn21">21</a> Postal (2003) observe que la référence aux opérations combinatoires installe subrepticement la conception dérivationnelle de la syntaxe, sans que l’option représentationnelle concurrente ait été minimalement discutée. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn22" id="ftn22">22</a> La notion de c-commande est définie en (13), chapitre IV.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn23" id="ftn23">23</a> C’est de façon impropre que l’on parle d’effacement de la copie, puisqu’il s’agit en réalité de l’effacement de l’élément source.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn24" id="ftn24">24</a> Il est nécessaire de distinguer les situations où on a affaire à un ensemble d’occurrences du même objet, présentes simultanément – c’est le cas lorsque cet objet a été déplacé –, de celles où deux objets identiques en tous points sont introduits indépendamment dans la structure. Le second cas est illustré en (i).</p>
<table class="example">
<tr>
<td></td>
<td>(i) </td>
<td>Les étudiants pensent que les étudiants sont exploités. </td>
</tr>
</table>
<p class="texte">Bref, le système doit pouvoir distinguer copie et répétition. Il semble que deux objets syntaxiques sont nécessairement interprétés comme des copies s’ils sont très proches l’un de l’autre. Selon Martin et Uriagereka (2014), la localité pertinente peut être définie sur la base de la notion de phase. Sur les phases, voir chapitres VII et VIII. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn25" id="ftn25">25</a> On admet provisoirement ici que le mouvement est la seule stratégie disponible permettant de légitimer casuellement l’expression <em>les étudiantes</em> en (9a). En (9c’), <del>les étudiantes</del> correspond à la copie du groupe nominal déplacé <em>les étudiantes</em>.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn26" id="ftn26">26</a> Les autres aspects biologiques du langage relèvent de la Faculté de Langage au sens large (FLB). Voir I, note 5.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn27" id="ftn27">27</a> C’est la position défendue dans <em>MI</em> et <em>DbP. </em>Dans <em>BEA</em>, <em>Move </em>n’est plus considéré comme une imperfection, mais comme un cas particulier de <em>Merge</em> (voir VII). </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn28" id="ftn28">28</a> Collins (1997) a largement contribué à ce changement de perspective.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn29" id="ftn29">29</a> (11a) est indépendamment exclu par des considérations casuelles. Dans sa position de surface, <em>a proof</em> ne peut valuer le trait de Cas ininterprétable qui lui est associé.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn30" id="ftn30">30</a> Sur le phénomène de super-montée et la Condition de minimalité, voir chapitres VII et IX.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn31" id="ftn31">31</a> Le symbole t<sub>i</sub> (pour « trace de i ») marque la position originelle de l’expression nominale antéposée d’indice i.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn32" id="ftn32">32</a> Sur cette asymétrie, voir la section 1 de ce chapitre, ainsi que la section 6 du chapitre I.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn33" id="ftn33">33</a> Bošković (1998) observe que cet argument n’exclut pas totalement l’insertion lexicale tardive. Il autorise l’insertion en LF d’éléments phonologiquement nuls et l’insertion en PF d’éléments sémantiquement nuls. Selon lui, la seconde option est illustrée par l’insertion de <em>do</em> en anglais, la première est impliquée dans les constructions à interrogatif in situ en français (voir X.1). L’insertion en LF ne peut concerner que des objets phonétiquement nuls, puisque, par définition, ces objets ne peuvent plus être prononcés. </p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn34" id="ftn34">34</a> Enfin, l’incertitude n’a pas été pleinement dissipée touchant la présence d’un trait [EPP] sur la catégorie T non fini dans les propositions infinitives à montée. Dans <em>BEA</em>, Chomsky donne un argument appuyant l’hypothèse d’un [EPP] sur le T non fini, voir VI.5.3.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn35" id="ftn35">35</a> Hinzen (2006) cite l’exemple suivant fourni par Martin et Uriagereka (2000) qui admet une seule représentation syntaxique en LF, mais deux interprétations sémantiques distinctes, selon que le meurtrier est un individu spécifique ou non.</p>
<table class="example">
<tr>
<td></td>
<td>(i) </td>
<td>Le meurtrier de Durand est fou.</td>
</tr>
</table>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn36" id="ftn36">36</a> Dans les chapitres qui suivent, je continuerai à désigner LF comme un niveau d’interface – ce qu’elle n’est pas dans le schéma (22) –, lorsque seront évoquées des propositions de Chomsky antérieures à <em>BEA.</em></p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn37" id="ftn37">37</a> En termes différents, on peut dire qu’il est nécessaire de distinguer entre la modularité <em>interne</em>, c’est-à-dire l’interaction entre la syntaxe et les composants externes, et la modularité <em>externe</em>, c’est-à-dire l’interaction entre la Faculté de Langage et les autres capacités cognitives.</p>
<p class="texte"><a class="FootnoteSymbol" href="#bodyftn38" id="ftn38">38</a> La seule interface qui pourrait être considérée est celle qui associe le Lexique et la Syntaxe. Pour un énoncé donné, on peut penser à la numération – la sélection prédéfinie d’items lexicaux auxquels s’appliquent les opérations syntaxiques – comme étant l’interface entre le Lexique et la Syntaxe. Il y a des raisons de penser que le Lexique, en tant que composant, ne doit pas être inclus dans la Faculté de Langage entendue au sens étroit. Voir aussi note 9. </p> </div><!-- #notes -->

</body>
</html>
